{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Feature Engineering\n",
        "\n",
        "This notebook computes rolling statistics, form metrics, and head-to-head features for backtesting.\n",
        "\n",
        "## Key Enhancements\n",
        "- Optimized rolling calculations using vectorized pandas operations\n",
        "- Efficient groupby with transform for parallel computation\n",
        "- Pre-computed team indices for O(1) lookup\n",
        "- Schema alignment with `ingest_all_data.py` features_metadata structure\n",
        "- Clear separation of PRE-MATCH vs POST-MATCH features\n",
        "\n",
        "## Features to Compute (All PRE-MATCH)\n",
        "1. Team form (last 5/10 games): W-D-L, points, goals, clean sheets\n",
        "2. Rolling stats: possession, shots, corners, fouls averages\n",
        "3. Home/away specific metrics\n",
        "4. Head-to-head history\n",
        "5. Match outcome labels (ground truth for backtesting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Feature Engineering Pipeline\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Optimize pandas for large datasets\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('compute.use_bottleneck', True)\n",
        "pd.set_option('compute.use_numexpr', True)\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "\n",
        "print(\"ðŸ“Š Feature Engineering Pipeline\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded 57,870 matches\n",
            "   Date range: 2024-01-01 05:00:00+00:00 to 2025-12-15 20:45:00+00:00\n",
            "   Memory usage: 39.58 MB\n"
          ]
        }
      ],
      "source": [
        "# Load cleaned matches\n",
        "matches = pd.read_parquet(PROCESSED_DIR / 'matches_base.parquet')\n",
        "matches['date'] = pd.to_datetime(matches['date'])\n",
        "matches = matches.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"âœ… Loaded {len(matches):,} matches\")\n",
        "print(f\"   Date range: {matches['date'].min()} to {matches['date'].max()}\")\n",
        "print(f\"   Memory usage: {matches.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Build Team Match History\n",
        "\n",
        "Create a unified view of all matches from each team's perspective for rolling calculations.\n",
        "This approach allows efficient computation of form metrics per team."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Built team history: 115,740 records\n",
            "   Unique teams: 4,049\n",
            "   Memory usage: 14.24 MB\n"
          ]
        }
      ],
      "source": [
        "def build_team_history(matches_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a unified team history DataFrame where each row represents\n",
        "    one team's participation in a match.\n",
        "    \n",
        "    This doubles the rows but enables efficient rolling calculations.\n",
        "    \"\"\"\n",
        "    # Define columns we need for both perspectives\n",
        "    base_cols = ['eventId', 'date', 'leagueId', 'tier']\n",
        "    \n",
        "    # Home team perspective\n",
        "    home_cols = base_cols + [\n",
        "        'homeTeamId', 'awayTeamId', \n",
        "        'homeTeamScore', 'awayTeamScore',\n",
        "        'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget',\n",
        "        'home_wonCorners', 'home_foulsCommitted', \n",
        "        'home_yellowCards', 'home_redCards'\n",
        "    ]\n",
        "    \n",
        "    # Filter to available columns\n",
        "    home_cols = [c for c in home_cols if c in matches_df.columns]\n",
        "    home = matches_df[home_cols].copy()\n",
        "    \n",
        "    # Rename to team-agnostic columns\n",
        "    rename_map = {\n",
        "        'homeTeamId': 'teamId',\n",
        "        'awayTeamId': 'opponentId',\n",
        "        'homeTeamScore': 'goals_for',\n",
        "        'awayTeamScore': 'goals_against',\n",
        "        'home_possessionPct': 'possession',\n",
        "        'home_totalShots': 'shots',\n",
        "        'home_shotsOnTarget': 'shots_on_target',\n",
        "        'home_wonCorners': 'corners',\n",
        "        'home_foulsCommitted': 'fouls',\n",
        "        'home_yellowCards': 'yellow_cards',\n",
        "        'home_redCards': 'red_cards'\n",
        "    }\n",
        "    home = home.rename(columns={k: v for k, v in rename_map.items() if k in home.columns})\n",
        "    home['is_home'] = True\n",
        "    \n",
        "    # Away team perspective\n",
        "    away_cols = base_cols + [\n",
        "        'awayTeamId', 'homeTeamId',\n",
        "        'awayTeamScore', 'homeTeamScore',\n",
        "        'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget',\n",
        "        'away_wonCorners', 'away_foulsCommitted',\n",
        "        'away_yellowCards', 'away_redCards'\n",
        "    ]\n",
        "    \n",
        "    away_cols = [c for c in away_cols if c in matches_df.columns]\n",
        "    away = matches_df[away_cols].copy()\n",
        "    \n",
        "    rename_map_away = {\n",
        "        'awayTeamId': 'teamId',\n",
        "        'homeTeamId': 'opponentId',\n",
        "        'awayTeamScore': 'goals_for',\n",
        "        'homeTeamScore': 'goals_against',\n",
        "        'away_possessionPct': 'possession',\n",
        "        'away_totalShots': 'shots',\n",
        "        'away_shotsOnTarget': 'shots_on_target',\n",
        "        'away_wonCorners': 'corners',\n",
        "        'away_foulsCommitted': 'fouls',\n",
        "        'away_yellowCards': 'yellow_cards',\n",
        "        'away_redCards': 'red_cards'\n",
        "    }\n",
        "    away = away.rename(columns={k: v for k, v in rename_map_away.items() if k in away.columns})\n",
        "    away['is_home'] = False\n",
        "    \n",
        "    # Combine and sort\n",
        "    history = pd.concat([home, away], ignore_index=True)\n",
        "    history = history.sort_values(['teamId', 'date']).reset_index(drop=True)\n",
        "    \n",
        "    # Compute derived fields (vectorized)\n",
        "    history['result'] = np.select(\n",
        "        [history['goals_for'] > history['goals_against'],\n",
        "         history['goals_for'] < history['goals_against']],\n",
        "        ['W', 'L'],\n",
        "        default='D'\n",
        "    )\n",
        "    history['points'] = history['result'].map({'W': 3, 'D': 1, 'L': 0})\n",
        "    history['clean_sheet'] = (history['goals_against'] == 0).astype('int8')\n",
        "    history['failed_to_score'] = (history['goals_for'] == 0).astype('int8')\n",
        "    \n",
        "    return history\n",
        "\n",
        "team_history = build_team_history(matches)\n",
        "print(f\"âœ… Built team history: {len(team_history):,} records\")\n",
        "print(f\"   Unique teams: {team_history['teamId'].nunique():,}\")\n",
        "print(f\"   Memory usage: {team_history.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Optimized Rolling Form Features\n",
        "\n",
        "Using vectorized pandas rolling operations with shifted windows to prevent data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing rolling form (5 games)...\n",
            "Computing rolling form (10 games)...\n",
            "âœ… Computed rolling form (5 & 10 games)\n"
          ]
        }
      ],
      "source": [
        "def compute_rolling_form(team_history: pd.DataFrame, n_games: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute rolling form metrics for each team before each match.\n",
        "    Uses shift(1) to ensure we only use data from BEFORE the current match.\n",
        "    \n",
        "    All features computed here are PRE-MATCH and safe for filter conditions.\n",
        "    \"\"\"\n",
        "    df = team_history.sort_values(['teamId', 'date']).copy()\n",
        "    \n",
        "    # Create boolean columns for efficient rolling\n",
        "    df['is_win'] = (df['result'] == 'W').astype('int8')\n",
        "    df['is_draw'] = (df['result'] == 'D').astype('int8')\n",
        "    df['is_loss'] = (df['result'] == 'L').astype('int8')\n",
        "    \n",
        "    # Group by team - this enables efficient parallel computation\n",
        "    grouped = df.groupby('teamId', sort=False)\n",
        "    \n",
        "    # Rolling metrics with shift(1) to exclude current match (PRE-MATCH only)\n",
        "    # These are all SAFE for filter conditions\n",
        "    \n",
        "    # Form counts (wins, draws, losses)\n",
        "    df[f'form_wins_{n_games}'] = grouped['is_win'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).sum()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    df[f'form_draws_{n_games}'] = grouped['is_draw'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).sum()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    df[f'form_losses_{n_games}'] = grouped['is_loss'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).sum()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    # Points and goals\n",
        "    df[f'form_points_{n_games}'] = grouped['points'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).sum()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    df[f'form_goals_scored_{n_games}'] = grouped['goals_for'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    df[f'form_goals_conceded_{n_games}'] = grouped['goals_against'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    df[f'form_clean_sheets_{n_games}'] = grouped['clean_sheet'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).sum()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    # Goal difference average\n",
        "    df['goal_diff'] = df['goals_for'] - df['goals_against']\n",
        "    df[f'form_goal_diff_{n_games}'] = grouped['goal_diff'].transform(\n",
        "        lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "    ).astype('float32')\n",
        "    \n",
        "    # Clean up temp columns\n",
        "    df = df.drop(columns=['is_win', 'is_draw', 'is_loss', 'goal_diff'], errors='ignore')\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Compute form for last 5 and 10 games\n",
        "print(\"Computing rolling form (5 games)...\")\n",
        "team_history = compute_rolling_form(team_history, n_games=5)\n",
        "print(\"Computing rolling form (10 games)...\")\n",
        "team_history = compute_rolling_form(team_history, n_games=10)\n",
        "\n",
        "print(f\"âœ… Computed rolling form (5 & 10 games)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Rolling Statistics (PRE-MATCH Averages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Computed rolling stats (5 games)\n"
          ]
        }
      ],
      "source": [
        "def compute_rolling_stats(team_history: pd.DataFrame, n_games: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute rolling averages for match statistics.\n",
        "    These represent the team's AVERAGE stats going into a match (PRE-MATCH).\n",
        "    \"\"\"\n",
        "    df = team_history.copy()\n",
        "    grouped = df.groupby('teamId', sort=False)\n",
        "    \n",
        "    stats_cols = ['possession', 'shots', 'shots_on_target', 'corners', 'fouls']\n",
        "    stats_cols = [c for c in stats_cols if c in df.columns]\n",
        "    \n",
        "    for col in stats_cols:\n",
        "        df[f'{col}_avg_{n_games}'] = grouped[col].transform(\n",
        "            lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "        ).astype('float32')\n",
        "    \n",
        "    return df\n",
        "\n",
        "team_history = compute_rolling_stats(team_history, n_games=5)\n",
        "print(f\"âœ… Computed rolling stats (5 games)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Home/Away Specific Form (PRE-MATCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Computed home/away specific form\n"
          ]
        }
      ],
      "source": [
        "def compute_venue_specific_form(team_history: pd.DataFrame, n_games: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute form metrics specific to home or away matches.\n",
        "    Uses efficient boolean indexing and vectorized operations.\n",
        "    \"\"\"\n",
        "    df = team_history.copy()\n",
        "    \n",
        "    # Home-specific form (only for home matches)\n",
        "    home_mask = df['is_home']\n",
        "    home_df = df.loc[home_mask].copy()\n",
        "    \n",
        "    if len(home_df) > 0:\n",
        "        home_grouped = home_df.groupby('teamId', sort=False)\n",
        "        \n",
        "        home_df[f'home_form_wins_{n_games}'] = home_grouped['result'].transform(\n",
        "            lambda x: (x == 'W').shift(1).rolling(n_games, min_periods=1).sum()\n",
        "        ).astype('float32')\n",
        "        \n",
        "        home_df[f'home_form_goals_{n_games}'] = home_grouped['goals_for'].transform(\n",
        "            lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "        ).astype('float32')\n",
        "    \n",
        "    # Away-specific form (only for away matches)\n",
        "    away_mask = ~df['is_home']\n",
        "    away_df = df.loc[away_mask].copy()\n",
        "    \n",
        "    if len(away_df) > 0:\n",
        "        away_grouped = away_df.groupby('teamId', sort=False)\n",
        "        \n",
        "        away_df[f'away_form_wins_{n_games}'] = away_grouped['result'].transform(\n",
        "            lambda x: (x == 'W').shift(1).rolling(n_games, min_periods=1).sum()\n",
        "        ).astype('float32')\n",
        "        \n",
        "        away_df[f'away_form_goals_{n_games}'] = away_grouped['goals_for'].transform(\n",
        "            lambda x: x.shift(1).rolling(n_games, min_periods=1).mean()\n",
        "        ).astype('float32')\n",
        "    \n",
        "    # Merge back efficiently using index alignment\n",
        "    home_cols = [c for c in home_df.columns if c.startswith('home_form_')]\n",
        "    away_cols = [c for c in away_df.columns if c.startswith('away_form_')]\n",
        "    \n",
        "    if home_cols:\n",
        "        df = df.merge(\n",
        "            home_df[['eventId', 'teamId'] + home_cols],\n",
        "            on=['eventId', 'teamId'],\n",
        "            how='left'\n",
        "        )\n",
        "    \n",
        "    if away_cols:\n",
        "        df = df.merge(\n",
        "            away_df[['eventId', 'teamId'] + away_cols],\n",
        "            on=['eventId', 'teamId'],\n",
        "            how='left'\n",
        "        )\n",
        "    \n",
        "    return df\n",
        "\n",
        "team_history = compute_venue_specific_form(team_history, n_games=5)\n",
        "print(f\"âœ… Computed home/away specific form\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Optimized Head-to-Head Features\n",
        "\n",
        "Using vectorized approach with pre-indexed lookups for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing H2H features...\n",
            "   Processing 12,468 unique team pairs...\n",
            "   Processed 10,000 matches...\n",
            "   Processed 20,000 matches...\n",
            "   Processed 30,000 matches...\n",
            "âœ… Computed H2H for 30,957 Tier 1/2 matches\n"
          ]
        }
      ],
      "source": [
        "def compute_h2h_features_optimized(matches_df: pd.DataFrame, max_lookback_days: int = 730) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute head-to-head history between teams for each match.\n",
        "    Optimized version using pre-indexed lookups.\n",
        "    \n",
        "    Parameters:\n",
        "    - max_lookback_days: Only consider H2H matches within this period (default 2 years)\n",
        "    \"\"\"\n",
        "    df = matches_df.copy()\n",
        "    \n",
        "    # Pre-compute team pair mappings\n",
        "    # Create sorted team pair keys for consistent lookup\n",
        "    df['team_pair'] = df.apply(\n",
        "        lambda r: tuple(sorted([r['homeTeamId'], r['awayTeamId']])), axis=1\n",
        "    )\n",
        "    \n",
        "    # Initialize H2H columns\n",
        "    h2h_cols = ['h2h_matches', 'h2h_home_wins', 'h2h_away_wins', 'h2h_draws', 'h2h_avg_goals']\n",
        "    for col in h2h_cols:\n",
        "        df[col] = np.nan\n",
        "    \n",
        "    # Group by team pair for efficient processing\n",
        "    print(f\"   Processing {df['team_pair'].nunique():,} unique team pairs...\")\n",
        "    \n",
        "    # Sort by date for chronological processing\n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Process each unique team pair\n",
        "    h2h_data = []\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        home_id = row['homeTeamId']\n",
        "        away_id = row['awayTeamId']\n",
        "        match_date = row['date']\n",
        "        cutoff_date = match_date - pd.Timedelta(days=max_lookback_days)\n",
        "        \n",
        "        # Find previous meetings within lookback period\n",
        "        prev_mask = (\n",
        "            (df['date'] < match_date) &\n",
        "            (df['date'] >= cutoff_date) &\n",
        "            (\n",
        "                ((df['homeTeamId'] == home_id) & (df['awayTeamId'] == away_id)) |\n",
        "                ((df['homeTeamId'] == away_id) & (df['awayTeamId'] == home_id))\n",
        "            )\n",
        "        )\n",
        "        prev_meetings = df.loc[prev_mask]\n",
        "        \n",
        "        if len(prev_meetings) == 0:\n",
        "            h2h_data.append({\n",
        "                'eventId': row['eventId'],\n",
        "                'h2h_matches': 0,\n",
        "                'h2h_home_wins': 0,\n",
        "                'h2h_away_wins': 0,\n",
        "                'h2h_draws': 0,\n",
        "                'h2h_avg_goals': None\n",
        "            })\n",
        "        else:\n",
        "            # Vectorized H2H calculation\n",
        "            home_wins = 0\n",
        "            away_wins = 0\n",
        "            draws = 0\n",
        "            \n",
        "            # Current home team's results in previous meetings\n",
        "            for _, m in prev_meetings.iterrows():\n",
        "                if m['homeTeamId'] == home_id:\n",
        "                    if m['homeTeamScore'] > m['awayTeamScore']:\n",
        "                        home_wins += 1\n",
        "                    elif m['homeTeamScore'] < m['awayTeamScore']:\n",
        "                        away_wins += 1\n",
        "                    else:\n",
        "                        draws += 1\n",
        "                else:\n",
        "                    if m['awayTeamScore'] > m['homeTeamScore']:\n",
        "                        home_wins += 1\n",
        "                    elif m['awayTeamScore'] < m['homeTeamScore']:\n",
        "                        away_wins += 1\n",
        "                    else:\n",
        "                        draws += 1\n",
        "            \n",
        "            total_goals = (prev_meetings['homeTeamScore'] + prev_meetings['awayTeamScore']).sum()\n",
        "            \n",
        "            h2h_data.append({\n",
        "                'eventId': row['eventId'],\n",
        "                'h2h_matches': len(prev_meetings),\n",
        "                'h2h_home_wins': home_wins,\n",
        "                'h2h_away_wins': away_wins,\n",
        "                'h2h_draws': draws,\n",
        "                'h2h_avg_goals': total_goals / len(prev_meetings)\n",
        "            })\n",
        "        \n",
        "        # Progress indicator\n",
        "        if (idx + 1) % 10000 == 0:\n",
        "            print(f\"   Processed {idx + 1:,} matches...\")\n",
        "    \n",
        "    h2h_df = pd.DataFrame(h2h_data)\n",
        "    \n",
        "    # Merge back\n",
        "    result = matches_df.merge(h2h_df, on='eventId', how='left')\n",
        "    result = result.drop(columns=['team_pair'], errors='ignore')\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Compute H2H for all matches (or sample for large datasets)\n",
        "print(\"Computing H2H features...\")\n",
        "\n",
        "# For efficiency, compute H2H for Tier 1 & 2 leagues first\n",
        "tier_12_matches = matches[matches['tier'].isin([1, 2])].copy()\n",
        "if len(tier_12_matches) > 0:\n",
        "    tier_12_with_h2h = compute_h2h_features_optimized(tier_12_matches)\n",
        "    print(f\"âœ… Computed H2H for {len(tier_12_with_h2h):,} Tier 1/2 matches\")\n",
        "else:\n",
        "    tier_12_with_h2h = None\n",
        "    print(\"   No Tier 1/2 matches found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compute Match Outcome Labels (Ground Truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Computed outcome labels\n",
            "\n",
            "ðŸ“Š Result Distribution:\n",
            "result\n",
            "H    0.451\n",
            "A    0.298\n",
            "D    0.250\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "ðŸ“Š Over 2.5 Goals: 49.3%\n",
            "ðŸ“Š BTTS: 49.3%\n"
          ]
        }
      ],
      "source": [
        "def compute_outcome_labels(matches_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute match outcome labels for backtesting evaluation.\n",
        "    These are POST-MATCH ground truth values, NOT for filter conditions.\n",
        "    \"\"\"\n",
        "    df = matches_df.copy()\n",
        "    \n",
        "    # Result (1X2) - vectorized\n",
        "    df['result'] = np.select(\n",
        "        [df['homeTeamScore'] > df['awayTeamScore'],\n",
        "         df['homeTeamScore'] < df['awayTeamScore']],\n",
        "        ['H', 'A'],\n",
        "        default='D'\n",
        "    )\n",
        "    \n",
        "    # Total goals\n",
        "    df['total_goals'] = (df['homeTeamScore'] + df['awayTeamScore']).astype('int16')\n",
        "    \n",
        "    # Over/Under thresholds - vectorized\n",
        "    df['over_0_5'] = (df['total_goals'] > 0.5).astype('int8')\n",
        "    df['over_1_5'] = (df['total_goals'] > 1.5).astype('int8')\n",
        "    df['over_2_5'] = (df['total_goals'] > 2.5).astype('int8')\n",
        "    df['over_3_5'] = (df['total_goals'] > 3.5).astype('int8')\n",
        "    \n",
        "    # Both Teams to Score\n",
        "    df['btts'] = ((df['homeTeamScore'] > 0) & (df['awayTeamScore'] > 0)).astype('int8')\n",
        "    \n",
        "    # Clean sheets\n",
        "    df['home_clean_sheet'] = (df['awayTeamScore'] == 0).astype('int8')\n",
        "    df['away_clean_sheet'] = (df['homeTeamScore'] == 0).astype('int8')\n",
        "    \n",
        "    return df\n",
        "\n",
        "matches = compute_outcome_labels(matches)\n",
        "print(f\"âœ… Computed outcome labels\")\n",
        "print(f\"\\nðŸ“Š Result Distribution:\")\n",
        "print(matches['result'].value_counts(normalize=True).round(3))\n",
        "print(f\"\\nðŸ“Š Over 2.5 Goals: {matches['over_2_5'].mean()*100:.1f}%\")\n",
        "print(f\"ðŸ“Š BTTS: {matches['btts'].mean()*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Merge Features Back to Matches\n",
        "\n",
        "Using indexed joins for efficient merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged team features to matches\n",
            "   Total columns: 107\n",
            "   Memory usage: 53.87 MB\n"
          ]
        }
      ],
      "source": [
        "def merge_team_features_to_matches(matches_df: pd.DataFrame, \n",
        "                                    team_history: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Merge computed team features back to the matches DataFrame.\n",
        "    Uses indexed merges for efficiency.\n",
        "    \"\"\"\n",
        "    # Identify feature columns to merge (PRE-MATCH features)\n",
        "    feature_cols = [col for col in team_history.columns \n",
        "                    if 'form_' in col or '_avg_' in col]\n",
        "    \n",
        "    # Home team features\n",
        "    home_features = team_history.loc[team_history['is_home'], ['eventId', 'teamId'] + feature_cols].copy()\n",
        "    home_features.columns = ['eventId', 'homeTeamId'] + [f'home_{col}' for col in feature_cols]\n",
        "    home_features = home_features.drop_duplicates(subset=['eventId', 'homeTeamId'])\n",
        "    \n",
        "    # Away team features\n",
        "    away_features = team_history.loc[~team_history['is_home'], ['eventId', 'teamId'] + feature_cols].copy()\n",
        "    away_features.columns = ['eventId', 'awayTeamId'] + [f'away_{col}' for col in feature_cols]\n",
        "    away_features = away_features.drop_duplicates(subset=['eventId', 'awayTeamId'])\n",
        "    \n",
        "    # Merge using indexed joins\n",
        "    df = matches_df.merge(home_features, on=['eventId', 'homeTeamId'], how='left')\n",
        "    df = df.merge(away_features, on=['eventId', 'awayTeamId'], how='left')\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Merge features\n",
        "matches_enriched = merge_team_features_to_matches(matches, team_history)\n",
        "print(f\"âœ… Merged team features to matches\")\n",
        "print(f\"   Total columns: {len(matches_enriched.columns)}\")\n",
        "print(f\"   Memory usage: {matches_enriched.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Enriched Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved enriched matches to ../data/processed/matches_enriched.parquet\n",
            "   Shape: (57870, 107)\n",
            "   Size: 4.82 MB\n",
            "âœ… Saved team history to ../data/processed/team_history.parquet\n"
          ]
        }
      ],
      "source": [
        "# Save enriched matches\n",
        "output_path = PROCESSED_DIR / 'matches_enriched.parquet'\n",
        "matches_enriched.to_parquet(output_path, index=False, compression='snappy')\n",
        "print(f\"âœ… Saved enriched matches to {output_path}\")\n",
        "print(f\"   Shape: {matches_enriched.shape}\")\n",
        "print(f\"   Size: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Save team history for reference\n",
        "history_path = PROCESSED_DIR / 'team_history.parquet'\n",
        "team_history.to_parquet(history_path, index=False, compression='snappy')\n",
        "print(f\"âœ… Saved team history to {history_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### PRE-MATCH Features (Safe for filter conditions):\n",
        "- **Form (5 & 10 games)**: wins, draws, losses, points, goals scored/conceded, clean sheets, goal diff\n",
        "- **Rolling stats (5 games)**: possession, shots, shots on target, corners, fouls averages\n",
        "- **Home/Away specific**: venue-specific form metrics\n",
        "- **H2H**: matches, wins, draws, avg goals (for Tier 1/2 leagues)\n",
        "\n",
        "### POST-MATCH Features (Ground truth only):\n",
        "- **Outcomes**: result (1X2), over/under, BTTS, clean sheets\n",
        "- **Match stats**: actual possession, shots, corners, etc.\n",
        "\n",
        "### Schema Alignment:\n",
        "Output matches `ingest_all_data.py` expected format for `features_metadata`.\n",
        "\n",
        "Next: `04_data_export.ipynb` for final validation and PostgreSQL export"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "filterbets-UjK3ofNw-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
