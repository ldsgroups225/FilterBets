{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Data Cleaning & Validation\n",
        "\n",
        "This notebook cleans and validates the raw ESPN Soccer data, preparing it for feature engineering.\n",
        "\n",
        "## Objectives\n",
        "1. Filter to completed matches only\n",
        "2. Remove duplicates and handle missing values\n",
        "3. Merge fixtures with team stats, teams, and leagues\n",
        "4. Apply league tier classification\n",
        "5. Output clean `matches_base.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ Loading data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path('../data')\n",
        "BASE_DATA = DATA_DIR / 'base_data'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "PROCESSED_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"ðŸ“‚ Loading data...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded fixtures: 67,353 rows\n",
            "âœ… Loaded teams: 4,144 rows\n",
            "âœ… Loaded leagues: 1,084 rows\n",
            "âœ… Loaded team_stats: 103,787 rows\n",
            "âœ… Loaded standings: 6,071 rows\n"
          ]
        }
      ],
      "source": [
        "# Load base tables\n",
        "fixtures = pd.read_csv(BASE_DATA / 'fixtures.csv')\n",
        "teams = pd.read_csv(BASE_DATA / 'teams.csv')\n",
        "leagues = pd.read_csv(BASE_DATA / 'leagues.csv')\n",
        "team_stats = pd.read_csv(BASE_DATA / 'teamStats.csv')\n",
        "standings = pd.read_csv(BASE_DATA / 'standings.csv')\n",
        "status = pd.read_csv(BASE_DATA / 'status.csv')\n",
        "\n",
        "print(f\"âœ… Loaded fixtures: {len(fixtures):,} rows\")\n",
        "print(f\"âœ… Loaded teams: {len(teams):,} rows\")\n",
        "print(f\"âœ… Loaded leagues: {len(leagues):,} rows\")\n",
        "print(f\"âœ… Loaded team_stats: {len(team_stats):,} rows\")\n",
        "print(f\"âœ… Loaded standings: {len(standings):,} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Filter to Completed Matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Completed matches: 57,870 (85.9% of total)\n",
            "ðŸ” Duplicate eventIds: 0\n"
          ]
        }
      ],
      "source": [
        "# Completed match status IDs\n",
        "COMPLETED_STATUSES = [\n",
        "    28,  # Full Time\n",
        "    45,  # Final - After Extra Time\n",
        "    46,  # Final - After Golden Goal\n",
        "    47,  # Final - After Penalties\n",
        "    51   # Final - Abandoned (but with result)\n",
        "]\n",
        "\n",
        "# Filter fixtures\n",
        "matches = fixtures[fixtures['statusId'].isin(COMPLETED_STATUSES)].copy()\n",
        "print(f\"ðŸ“Š Completed matches: {len(matches):,} ({len(matches)/len(fixtures)*100:.1f}% of total)\")\n",
        "\n",
        "# Check for duplicates\n",
        "duplicates = matches['eventId'].duplicated().sum()\n",
        "print(f\"ðŸ” Duplicate eventIds: {duplicates}\")\n",
        "if duplicates > 0:\n",
        "    matches = matches.drop_duplicates(subset='eventId', keep='first')\n",
        "    print(f\"   Removed {duplicates} duplicates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Standardize Date Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“… Date range: 2024-01-01 05:00:00+00:00 to 2025-12-15 20:45:00+00:00\n",
            "   Total days: 714\n"
          ]
        }
      ],
      "source": [
        "# Convert date to datetime\n",
        "matches['date'] = pd.to_datetime(matches['date'], utc=True)\n",
        "matches = matches.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"ðŸ“… Date range: {matches['date'].min()} to {matches['date'].max()}\")\n",
        "print(f\"   Total days: {(matches['date'].max() - matches['date'].min()).days}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. League Tier Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ† League Tier Distribution:\n",
            "tier\n",
            "1      5\n",
            "2     12\n",
            "3    203\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Define league tiers\n",
        "TIER_1_MIDSIZE = ['ENG.1', 'ESP.1', 'ITA.1', 'GER.1', 'FRA.1']\n",
        "TIER_2_MIDSIZE = ['NED.1', 'POR.1', 'BEL.1', 'TUR.1', 'SCO.1', \n",
        "                  'UEFA.CHAMPIONS', 'UEFA.EUROPA', 'ENG.2', 'ESP.2', \n",
        "                  'ITA.2', 'GER.2', 'FRA.2']\n",
        "\n",
        "# Create league lookup with tier\n",
        "league_lookup = leagues[['leagueId', 'midsizeName', 'leagueName', 'year']].drop_duplicates(subset='leagueId')\n",
        "\n",
        "def assign_tier(midsize):\n",
        "    if midsize in TIER_1_MIDSIZE:\n",
        "        return 1\n",
        "    elif midsize in TIER_2_MIDSIZE:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "league_lookup['tier'] = league_lookup['midsizeName'].apply(assign_tier)\n",
        "\n",
        "print(\"ðŸ† League Tier Distribution:\")\n",
        "print(league_lookup['tier'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Merge with Team Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged team names\n",
            "   Missing home team names: 0\n",
            "   Missing away team names: 0\n"
          ]
        }
      ],
      "source": [
        "# Prepare team lookup\n",
        "team_lookup = teams[['teamId', 'displayName', 'shortDisplayName']].copy()\n",
        "team_lookup.columns = ['teamId', 'team_name', 'team_short_name']\n",
        "\n",
        "# Merge home team\n",
        "matches = matches.merge(\n",
        "    team_lookup.rename(columns={'teamId': 'homeTeamId', \n",
        "                                'team_name': 'home_team_name',\n",
        "                                'team_short_name': 'home_team_short'}),\n",
        "    on='homeTeamId',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge away team\n",
        "matches = matches.merge(\n",
        "    team_lookup.rename(columns={'teamId': 'awayTeamId',\n",
        "                                'team_name': 'away_team_name',\n",
        "                                'team_short_name': 'away_team_short'}),\n",
        "    on='awayTeamId',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Merged team names\")\n",
        "print(f\"   Missing home team names: {matches['home_team_name'].isna().sum()}\")\n",
        "print(f\"   Missing away team names: {matches['away_team_name'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Merge with League Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged league info\n",
            "\n",
            "ðŸ“Š Matches by Tier:\n",
            "tier\n",
            "1.0     2472\n",
            "2.0     5653\n",
            "3.0    49237\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Merge league info\n",
        "matches = matches.merge(\n",
        "    league_lookup[['leagueId', 'midsizeName', 'leagueName', 'tier']].rename(\n",
        "        columns={'midsizeName': 'league_code', 'leagueName': 'league_name'}\n",
        "    ),\n",
        "    on='leagueId',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Merged league info\")\n",
        "print(f\"\\nðŸ“Š Matches by Tier:\")\n",
        "print(matches['tier'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Merge with Team Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Home stats records: 51,873\n",
            "ðŸ“Š Away stats records: 51,914\n"
          ]
        }
      ],
      "source": [
        "# Key stats columns to keep\n",
        "STATS_COLS = [\n",
        "    'eventId', 'teamId', 'teamOrder',\n",
        "    'possessionPct', 'foulsCommitted', 'yellowCards', 'redCards',\n",
        "    'offsides', 'wonCorners', 'saves', 'totalShots', 'shotsOnTarget',\n",
        "    'shotPct', 'accuratePasses', 'totalPasses', 'passPct'\n",
        "]\n",
        "\n",
        "stats_subset = team_stats[STATS_COLS].copy()\n",
        "\n",
        "# Split into home (teamOrder=0) and away (teamOrder=1)\n",
        "home_stats = stats_subset[stats_subset['teamOrder'] == 0].copy()\n",
        "away_stats = stats_subset[stats_subset['teamOrder'] == 1].copy()\n",
        "\n",
        "# Rename columns for home stats\n",
        "home_stats_cols = {col: f'home_{col}' for col in STATS_COLS if col not in ['eventId', 'teamId', 'teamOrder']}\n",
        "home_stats = home_stats.rename(columns=home_stats_cols)\n",
        "home_stats = home_stats.drop(columns=['teamId', 'teamOrder'])\n",
        "\n",
        "# Rename columns for away stats\n",
        "away_stats_cols = {col: f'away_{col}' for col in STATS_COLS if col not in ['eventId', 'teamId', 'teamOrder']}\n",
        "away_stats = away_stats.rename(columns=away_stats_cols)\n",
        "away_stats = away_stats.drop(columns=['teamId', 'teamOrder'])\n",
        "\n",
        "print(f\"ðŸ“Š Home stats records: {len(home_stats):,}\")\n",
        "print(f\"ðŸ“Š Away stats records: {len(away_stats):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged team stats\n",
            "   Stats coverage: 48.8%\n"
          ]
        }
      ],
      "source": [
        "# Merge stats with matches\n",
        "matches = matches.merge(home_stats, on='eventId', how='left')\n",
        "matches = matches.merge(away_stats, on='eventId', how='left')\n",
        "\n",
        "# Check coverage\n",
        "stats_coverage = matches['home_possessionPct'].notna().sum() / len(matches) * 100\n",
        "print(f\"âœ… Merged team stats\")\n",
        "print(f\"   Stats coverage: {stats_coverage:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Handle Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Filling 24 stats columns with 0 for missing values\n",
            "âœ… Remaining nulls in stats columns: 0\n"
          ]
        }
      ],
      "source": [
        "# Fill missing numeric stats with 0 (conservative approach)\n",
        "stats_columns = [col for col in matches.columns if col.startswith(('home_', 'away_')) \n",
        "                 and any(s in col for s in ['Pct', 'Shots', 'Corners', 'Cards', 'Passes', 'fouls', 'offsides', 'saves'])]\n",
        "\n",
        "print(f\"ðŸ“Š Filling {len(stats_columns)} stats columns with 0 for missing values\")\n",
        "\n",
        "for col in stats_columns:\n",
        "    missing_before = matches[col].isna().sum()\n",
        "    if missing_before > 0:\n",
        "        matches[col] = matches[col].fillna(0)\n",
        "\n",
        "# Verify\n",
        "remaining_nulls = matches[stats_columns].isna().sum().sum()\n",
        "print(f\"âœ… Remaining nulls in stats columns: {remaining_nulls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Data Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Data Validation\n",
            "==================================================\n",
            "   Max home score: 16\n",
            "   Max away score: 19\n",
            "   Matches with score > 10: 29\n",
            "   Invalid possession (>100%): 0\n",
            "\n",
            "âœ… Validation complete\n"
          ]
        }
      ],
      "source": [
        "# Validate data integrity\n",
        "print(\"ðŸ” Data Validation\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check score ranges\n",
        "max_home_score = matches['homeTeamScore'].max()\n",
        "max_away_score = matches['awayTeamScore'].max()\n",
        "print(f\"   Max home score: {max_home_score}\")\n",
        "print(f\"   Max away score: {max_away_score}\")\n",
        "\n",
        "# Flag anomalous scores (>10 goals)\n",
        "anomalous = matches[(matches['homeTeamScore'] > 10) | (matches['awayTeamScore'] > 10)]\n",
        "print(f\"   Matches with score > 10: {len(anomalous)}\")\n",
        "\n",
        "# Check possession ranges\n",
        "if 'home_possessionPct' in matches.columns:\n",
        "    invalid_possession = matches[\n",
        "        (matches['home_possessionPct'] > 100) | \n",
        "        (matches['away_possessionPct'] > 100)\n",
        "    ]\n",
        "    print(f\"   Invalid possession (>100%): {len(invalid_possession)}\")\n",
        "\n",
        "print(\"\\nâœ… Validation complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Select Final Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Final columns: 39\n",
            "ðŸ“Š Final rows: 59,550\n"
          ]
        }
      ],
      "source": [
        "# Define final column order\n",
        "FINAL_COLUMNS = [\n",
        "    # Match identifiers\n",
        "    'eventId', 'date', 'leagueId', 'league_code', 'league_name', 'tier',\n",
        "    'venueId', 'attendance',\n",
        "    \n",
        "    # Teams\n",
        "    'homeTeamId', 'home_team_name', 'home_team_short',\n",
        "    'awayTeamId', 'away_team_name', 'away_team_short',\n",
        "    \n",
        "    # Scores\n",
        "    'homeTeamScore', 'awayTeamScore',\n",
        "    'homeTeamWinner', 'awayTeamWinner',\n",
        "    \n",
        "    # Home team stats\n",
        "    'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget',\n",
        "    'home_wonCorners', 'home_foulsCommitted', 'home_yellowCards', 'home_redCards',\n",
        "    'home_accuratePasses', 'home_totalPasses', 'home_passPct',\n",
        "    \n",
        "    # Away team stats\n",
        "    'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget',\n",
        "    'away_wonCorners', 'away_foulsCommitted', 'away_yellowCards', 'away_redCards',\n",
        "    'away_accuratePasses', 'away_totalPasses', 'away_passPct',\n",
        "    \n",
        "    # Status\n",
        "    'statusId'\n",
        "]\n",
        "\n",
        "# Select columns that exist\n",
        "available_cols = [col for col in FINAL_COLUMNS if col in matches.columns]\n",
        "matches_clean = matches[available_cols].copy()\n",
        "\n",
        "print(f\"ðŸ“‹ Final columns: {len(available_cols)}\")\n",
        "print(f\"ðŸ“Š Final rows: {len(matches_clean):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Export Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved to ../data/processed/matches_base.parquet\n",
            "   File size: 2.39 MB\n",
            "âœ… Saved leagues to ../data/processed/leagues_clean.parquet\n"
          ]
        }
      ],
      "source": [
        "# Save to parquet\n",
        "output_path = PROCESSED_DIR / 'matches_base.parquet'\n",
        "matches_clean.to_parquet(output_path, index=False)\n",
        "\n",
        "print(f\"âœ… Saved to {output_path}\")\n",
        "print(f\"   File size: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Also save league lookup\n",
        "league_output = PROCESSED_DIR / 'leagues_clean.parquet'\n",
        "league_lookup.to_parquet(league_output, index=False)\n",
        "print(f\"âœ… Saved leagues to {league_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ðŸ“Š CLEANING SUMMARY\n",
            "==================================================\n",
            "   Input fixtures: 67,353\n",
            "   Output matches: 59,550\n",
            "   Tier 1 matches: 2,472\n",
            "   Tier 2 matches: 5,798\n",
            "   Tier 3 matches: 50,736\n",
            "\n",
            "   Stats coverage: 48.6%\n"
          ]
        }
      ],
      "source": [
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ðŸ“Š CLEANING SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"   Input fixtures: {len(fixtures):,}\")\n",
        "print(f\"   Output matches: {len(matches_clean):,}\")\n",
        "print(f\"   Tier 1 matches: {len(matches_clean[matches_clean['tier'] == 1]):,}\")\n",
        "print(f\"   Tier 2 matches: {len(matches_clean[matches_clean['tier'] == 2]):,}\")\n",
        "print(f\"   Tier 3 matches: {len(matches_clean[matches_clean['tier'] == 3]):,}\")\n",
        "print(f\"\\n   Stats coverage: {(matches_clean['home_possessionPct'] > 0).sum() / len(matches_clean) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next: 03_feature_engineering.ipynb\n",
        "\n",
        "The clean `matches_base.parquet` is ready for feature engineering:\n",
        "- Rolling form calculations (last 5/10 games)\n",
        "- Home/away specific metrics\n",
        "- Head-to-head history\n",
        "- Pre-match standings context"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "filterbets-UjK3ofNw-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
