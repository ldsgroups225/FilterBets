{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Data Cleaning & Validation\n",
        "\n",
        "This notebook cleans and validates the raw ESPN Soccer data, preparing it for feature engineering.\n",
        "\n",
        "## Objectives\n",
        "1. Filter to completed matches only\n",
        "2. Remove duplicates and handle missing values\n",
        "3. Merge fixtures with team stats, teams, and leagues\n",
        "4. Apply comprehensive league tier classification (60+ leagues)\n",
        "5. Optimize joins and relationships for efficiency\n",
        "6. Output clean `matches_base.parquet`\n",
        "\n",
        "## Key Enhancements\n",
        "- Efficient batch processing with vectorized operations\n",
        "- Pre-match vs post-match field distinction\n",
        "- Improved relationship handling with merge optimization\n",
        "- Schema alignment with `ingest_all_data.py`\n",
        "- Comprehensive global league coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ Data Cleaning Pipeline Started\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = Path('../data')\n",
        "BASE_DATA = DATA_DIR / 'base_data'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "PROCESSED_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"ðŸ“‚ Data Cleaning Pipeline Started\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Raw Data with Optimized dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data with optimized memory...\n",
            "âœ… Loaded fixtures: 67,353 rows (11.82 MB)\n",
            "âœ… Loaded teams: 4,144 rows\n",
            "âœ… Loaded leagues: 1,084 rows\n",
            "âœ… Loaded team_stats: 103,787 rows (25.44 MB)\n",
            "âœ… Loaded standings: 6,071 rows\n"
          ]
        }
      ],
      "source": [
        "# Define optimal dtypes for memory efficiency\n",
        "FIXTURE_DTYPES = {\n",
        "    'Rn': 'int32',\n",
        "    'seasonType': 'int32',\n",
        "    'leagueId': 'int32',\n",
        "    'eventId': 'int64',\n",
        "    'venueId': 'int32',\n",
        "    'attendance': 'int32',\n",
        "    'homeTeamId': 'int32',\n",
        "    'awayTeamId': 'int32',\n",
        "    'homeTeamScore': 'int16',\n",
        "    'awayTeamScore': 'int16',\n",
        "    'homeTeamShootoutScore': 'int16',\n",
        "    'awayTeamShootoutScore': 'int16',\n",
        "    'statusId': 'int16'\n",
        "}\n",
        "\n",
        "TEAM_STATS_DTYPES = {\n",
        "    'seasonType': 'int32',\n",
        "    'eventId': 'int64',\n",
        "    'teamId': 'int32',\n",
        "    'teamOrder': 'int8',\n",
        "    'possessionPct': 'float32',\n",
        "    'foulsCommitted': 'float32',\n",
        "    'yellowCards': 'float32',\n",
        "    'redCards': 'float32',\n",
        "    'offsides': 'float32',\n",
        "    'wonCorners': 'float32',\n",
        "    'saves': 'float32',\n",
        "    'totalShots': 'float32',\n",
        "    'shotsOnTarget': 'float32',\n",
        "    'shotPct': 'float32',\n",
        "    'accuratePasses': 'float32',\n",
        "    'totalPasses': 'float32',\n",
        "    'passPct': 'float32'\n",
        "}\n",
        "\n",
        "# Load base tables with optimized dtypes\n",
        "print(\"Loading data with optimized memory...\")\n",
        "fixtures = pd.read_csv(BASE_DATA / 'fixtures.csv', dtype=FIXTURE_DTYPES)\n",
        "teams = pd.read_csv(BASE_DATA / 'teams.csv')\n",
        "leagues = pd.read_csv(BASE_DATA / 'leagues.csv')\n",
        "team_stats = pd.read_csv(BASE_DATA / 'teamStats.csv', dtype=TEAM_STATS_DTYPES)\n",
        "standings = pd.read_csv(BASE_DATA / 'standings.csv')\n",
        "status = pd.read_csv(BASE_DATA / 'status.csv')\n",
        "\n",
        "print(f\"âœ… Loaded fixtures: {len(fixtures):,} rows ({fixtures.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB)\")\n",
        "print(f\"âœ… Loaded teams: {len(teams):,} rows\")\n",
        "print(f\"âœ… Loaded leagues: {len(leagues):,} rows\")\n",
        "print(f\"âœ… Loaded team_stats: {len(team_stats):,} rows ({team_stats.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB)\")\n",
        "print(f\"âœ… Loaded standings: {len(standings):,} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Filter to Completed Matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Completed matches: 57,870 (85.9% of total)\n",
            "ðŸ” Unique eventIds: 57,870\n"
          ]
        }
      ],
      "source": [
        "# Completed match status IDs\n",
        "COMPLETED_STATUSES = [\n",
        "    28,  # Full Time\n",
        "    45,  # Final - After Extra Time\n",
        "    46,  # Final - After Golden Goal\n",
        "    47,  # Final - After Penalties\n",
        "    51   # Final - Abandoned (but with result)\n",
        "]\n",
        "\n",
        "# Filter fixtures using vectorized operation\n",
        "mask = fixtures['statusId'].isin(COMPLETED_STATUSES)\n",
        "matches = fixtures.loc[mask].copy()\n",
        "print(f\"ðŸ“Š Completed matches: {len(matches):,} ({len(matches)/len(fixtures)*100:.1f}% of total)\")\n",
        "\n",
        "# Check and remove duplicates efficiently\n",
        "dup_mask = matches.duplicated(subset='eventId', keep='first')\n",
        "n_dups = dup_mask.sum()\n",
        "if n_dups > 0:\n",
        "    matches = matches.loc[~dup_mask]\n",
        "    print(f\"   Removed {n_dups} duplicates\")\n",
        "print(f\"ðŸ” Unique eventIds: {matches['eventId'].nunique():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Standardize Date Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“… Date range: 2024-01-01 05:00:00+00:00 to 2025-12-15 20:45:00+00:00\n",
            "   Total days: 714\n"
          ]
        }
      ],
      "source": [
        "# Convert date with UTC timezone\n",
        "matches['date'] = pd.to_datetime(matches['date'], utc=True)\n",
        "matches = matches.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"ðŸ“… Date range: {matches['date'].min()} to {matches['date'].max()}\")\n",
        "print(f\"   Total days: {(matches['date'].max() - matches['date'].min()).days}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comprehensive League Tier Classification\n",
        "\n",
        "60+ leagues across Europe, Americas, Asia, and Africa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ† League Tier Distribution:\n",
            "   Tier 1: 5 leagues\n",
            "   Tier 2: 61 leagues\n",
            "   Tier 3: 154 leagues\n",
            "\n",
            "   Tier 1 leagues: 5\n",
            "   Tier 2 leagues: 83\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMPREHENSIVE LEAGUE TIER CLASSIFICATION\n",
        "# ============================================================\n",
        "\n",
        "# TIER 1 - Top 5 European Leagues (Highest data quality and betting interest)\n",
        "TIER_1_MIDSIZE = {'ENG.1', 'ESP.1', 'ITA.1', 'GER.1', 'FRA.1'}\n",
        "\n",
        "# TIER 2 - Comprehensive global coverage (50+ leagues)\n",
        "TIER_2_MIDSIZE = {\n",
        "    # Second tier of major European leagues\n",
        "    'ENG.2', 'ENG.3', 'ENG.4', 'ENG.5',  # English pyramid\n",
        "    'ESP.2', 'ITA.2', 'GER.2', 'FRA.2',\n",
        "    \n",
        "    # Other top European first divisions\n",
        "    'NED.1', 'NED.2',  # Netherlands\n",
        "    'POR.1', 'POR.2',  # Portugal\n",
        "    'BEL.1',           # Belgium\n",
        "    'TUR.1', 'TUR.2',  # Turkey\n",
        "    'RUS.1',           # Russia\n",
        "    'UKR.1',           # Ukraine\n",
        "    'SCO.1', 'SCO.2',  # Scotland\n",
        "    'AUT.1',           # Austria\n",
        "    'SUI.1',           # Switzerland\n",
        "    'GRE.1',           # Greece\n",
        "    'DEN.1',           # Denmark\n",
        "    'NOR.1',           # Norway\n",
        "    'SWE.1',           # Sweden\n",
        "    'FIN.1',           # Finland\n",
        "    'POL.1',           # Poland\n",
        "    'CZE.1',           # Czech Republic\n",
        "    'CRO.1',           # Croatia\n",
        "    'SRB.1',           # Serbia\n",
        "    'ROM.1',           # Romania\n",
        "    'BUL.1',           # Bulgaria\n",
        "    'HUN.1',           # Hungary\n",
        "    'CYP.1',           # Cyprus\n",
        "    'ISR.1',           # Israel\n",
        "    \n",
        "    # European competitions\n",
        "    'UEFA.CHAMPIONS', 'UEFA.EUROPA', 'UEFA.EUROPA.CONF',\n",
        "    \n",
        "    # Americas - North & Central\n",
        "    'USA.1', 'USA.2',           # USA MLS & USL\n",
        "    'MEX.1', 'MEX.2',           # Mexico\n",
        "    'CAN.1',                    # Canada\n",
        "    'CRC.1',                    # Costa Rica\n",
        "    'CONCACAF.CHAMPIONS',       # CONCACAF Champions League\n",
        "    \n",
        "    # Americas - South\n",
        "    'BRA.1', 'BRA.2',           # Brazil\n",
        "    'ARG.1', 'ARG.2',           # Argentina\n",
        "    'COL.1',                    # Colombia\n",
        "    'CHI.1',                    # Chile\n",
        "    'PER.1',                    # Peru\n",
        "    'ECU.1',                    # Ecuador\n",
        "    'URU.1',                    # Uruguay\n",
        "    'PAR.1',                    # Paraguay\n",
        "    'VEN.1',                    # Venezuela\n",
        "    'BOL.1',                    # Bolivia\n",
        "    'CONMEBOL.LIBERTADORES',    # Copa Libertadores\n",
        "    'CONMEBOL.SUDAMERICANA',    # Copa Sudamericana\n",
        "    \n",
        "    # Asia & Oceania\n",
        "    'JPN.1', 'JPN.2',           # Japan J-League\n",
        "    'KOR.1',                    # South Korea K-League\n",
        "    'CHN.1',                    # China Super League\n",
        "    'AUS.1',                    # Australia A-League\n",
        "    'SAU.1',                    # Saudi Arabia\n",
        "    'UAE.1',                    # UAE\n",
        "    'QAT.1',                    # Qatar\n",
        "    'IND.1',                    # India ISL\n",
        "    'THA.1',                    # Thailand\n",
        "    'IDN.1',                    # Indonesia\n",
        "    'MYS.1',                    # Malaysia\n",
        "    'AFC.CHAMPIONS',            # AFC Champions League\n",
        "    \n",
        "    # Africa\n",
        "    'RSA.1',                    # South Africa PSL\n",
        "    'EGY.1',                    # Egypt\n",
        "    'MAR.1',                    # Morocco\n",
        "    'TUN.1',                    # Tunisia\n",
        "    'ALG.1',                    # Algeria\n",
        "    'NGA.1',                    # Nigeria\n",
        "    'GHA.1',                    # Ghana\n",
        "    'KEN.1',                    # Kenya\n",
        "    'UGA.1',                    # Uganda\n",
        "    'CAF.CHAMPIONS',            # CAF Champions League\n",
        "    'CAF.CONFED'                # CAF Confederation Cup\n",
        "}\n",
        "\n",
        "# Create league lookup with tier using vectorized assignment\n",
        "league_lookup = leagues[['leagueId', 'midsizeName', 'leagueName', 'year']].drop_duplicates(subset='leagueId').copy()\n",
        "\n",
        "# Vectorized tier assignment\n",
        "league_lookup['tier'] = np.select(\n",
        "    [league_lookup['midsizeName'].isin(TIER_1_MIDSIZE),\n",
        "     league_lookup['midsizeName'].isin(TIER_2_MIDSIZE)],\n",
        "    [1, 2],\n",
        "    default=3\n",
        ")\n",
        "\n",
        "print(\"ðŸ† League Tier Distribution:\")\n",
        "tier_counts = league_lookup['tier'].value_counts().sort_index()\n",
        "for tier, count in tier_counts.items():\n",
        "    print(f\"   Tier {tier}: {count} leagues\")\n",
        "print(f\"\\n   Tier 1 leagues: {len(TIER_1_MIDSIZE)}\")\n",
        "print(f\"   Tier 2 leagues: {len(TIER_2_MIDSIZE)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Optimized Relationship Merging\n",
        "\n",
        "Using indexed merges for better performance on large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating indexed lookups for efficient merging...\n",
            "âœ… Merged team names \n",
            "   Missing home team names: 0\n",
            "   Missing away team names: 0\n"
          ]
        }
      ],
      "source": [
        "# Create indexed lookup dictionaries for O(1) access\n",
        "print(\"Creating indexed lookups for efficient merging...\")\n",
        "\n",
        "# Team lookup - create once, reuse twice\n",
        "team_lookup = teams.set_index('teamId')[['displayName', 'shortDisplayName', 'logoURL']].to_dict('index')\n",
        "\n",
        "# Add home team info using vectorized map\n",
        "matches['home_team_name'] = matches['homeTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('displayName', '')\n",
        ")\n",
        "matches['home_team_short'] = matches['homeTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('shortDisplayName', '')\n",
        ")\n",
        "matches['home_team_logo'] = matches['homeTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('logoURL', '')\n",
        ")\n",
        "\n",
        "# Add away team info\n",
        "matches['away_team_name'] = matches['awayTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('displayName', '')\n",
        ")\n",
        "matches['away_team_short'] = matches['awayTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('shortDisplayName', '')\n",
        ")\n",
        "matches['away_team_logo'] = matches['awayTeamId'].map(\n",
        "    lambda x: team_lookup.get(x, {}).get('logoURL', '')\n",
        ")\n",
        "\n",
        "print(f\"âœ… Merged team names \")\n",
        "print(f\"   Missing home team names: {(matches['home_team_name'] == '').sum()}\")\n",
        "print(f\"   Missing away team names: {(matches['away_team_name'] == '').sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged league info\n",
            "\n",
            "ðŸ“Š Matches by Tier:\n",
            "   Tier 1.0: 2,472 (4.3%)\n",
            "   Tier 2.0: 28,485 (49.2%)\n",
            "   Tier 3.0: 26,405 (45.6%)\n"
          ]
        }
      ],
      "source": [
        "# League lookup using indexed merge for efficiency\n",
        "league_idx = league_lookup.set_index('leagueId')[['midsizeName', 'leagueName', 'tier']]\n",
        "\n",
        "matches = matches.merge(\n",
        "    league_idx.rename(columns={'midsizeName': 'league_code', 'leagueName': 'league_name'}),\n",
        "    left_on='leagueId',\n",
        "    right_index=True,\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Merged league info\")\n",
        "print(f\"\\nðŸ“Š Matches by Tier:\")\n",
        "tier_match_counts = matches['tier'].value_counts().sort_index()\n",
        "for tier, count in tier_match_counts.items():\n",
        "    print(f\"   Tier {tier}: {count:,} ({count/len(matches)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Optimized Team Stats Merge\n",
        "\n",
        "Using pivot operations for efficient home/away stats splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Home stats records: 51,209\n",
            "ðŸ“Š Away stats records: 51,209\n"
          ]
        }
      ],
      "source": [
        "# Key stats columns - these are POST-MATCH fields\n",
        "# Note: For backtesting filters, these should only be used as ground truth,\n",
        "# not as filter conditions (to avoid look-ahead bias)\n",
        "STATS_COLS = [\n",
        "    'possessionPct', 'foulsCommitted', 'yellowCards', 'redCards',\n",
        "    'offsides', 'wonCorners', 'saves', 'totalShots', 'shotsOnTarget',\n",
        "    'shotPct', 'accuratePasses', 'totalPasses', 'passPct'\n",
        "]\n",
        "\n",
        "# Filter to relevant columns only\n",
        "stats_subset = team_stats[['eventId', 'teamId', 'teamOrder'] + STATS_COLS].copy()\n",
        "\n",
        "# Split and pivot in one operation for efficiency\n",
        "home_mask = stats_subset['teamOrder'] == 0\n",
        "away_mask = stats_subset['teamOrder'] == 1\n",
        "\n",
        "# Home stats\n",
        "home_stats = stats_subset.loc[home_mask].drop(columns=['teamId', 'teamOrder'])\n",
        "home_stats.columns = ['eventId'] + [f'home_{col}' for col in STATS_COLS]\n",
        "home_stats = home_stats.drop_duplicates(subset='eventId')\n",
        "\n",
        "# Away stats\n",
        "away_stats = stats_subset.loc[away_mask].drop(columns=['teamId', 'teamOrder'])\n",
        "away_stats.columns = ['eventId'] + [f'away_{col}' for col in STATS_COLS]\n",
        "away_stats = away_stats.drop_duplicates(subset='eventId')\n",
        "\n",
        "print(f\"ðŸ“Š Home stats records: {len(home_stats):,}\")\n",
        "print(f\"ðŸ“Š Away stats records: {len(away_stats):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Merged team stats\n",
            "   Stats coverage: 48.9%\n"
          ]
        }
      ],
      "source": [
        "# Use indexed merge for better performance\n",
        "home_stats_idx = home_stats.set_index('eventId')\n",
        "away_stats_idx = away_stats.set_index('eventId')\n",
        "\n",
        "matches = matches.merge(home_stats_idx, left_on='eventId', right_index=True, how='left')\n",
        "matches = matches.merge(away_stats_idx, left_on='eventId', right_index=True, how='left')\n",
        "\n",
        "# Check coverage\n",
        "stats_coverage = matches['home_possessionPct'].notna().mean() * 100\n",
        "print(f\"âœ… Merged team stats\")\n",
        "print(f\"   Stats coverage: {stats_coverage:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Handle Missing Values with Proper Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Processing 26 stats columns...\n",
            "âœ… Filled missing values. Remaining nulls in stats: 0\n"
          ]
        }
      ],
      "source": [
        "# Fill missing numeric stats with 0 (conservative approach for matches without detailed stats)\n",
        "stats_columns = [f'home_{col}' for col in STATS_COLS] + [f'away_{col}' for col in STATS_COLS]\n",
        "\n",
        "print(f\"ðŸ“Š Processing {len(stats_columns)} stats columns...\")\n",
        "\n",
        "# Vectorized fill for efficiency\n",
        "for col in stats_columns:\n",
        "    if col in matches.columns:\n",
        "        matches[col] = matches[col].fillna(0)\n",
        "\n",
        "# Verify\n",
        "remaining_nulls = matches[stats_columns].isna().sum().sum()\n",
        "print(f\"âœ… Filled missing values. Remaining nulls in stats: {remaining_nulls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Data Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Data Validation\n",
            "==================================================\n",
            "   Max home score: 16\n",
            "   Max away score: 19\n",
            "   Matches with score > 10: 26\n",
            "   Invalid possession (>100%): 0\n",
            "   Matches with same home/away team: 0\n",
            "\n",
            "âœ… Validation complete\n"
          ]
        }
      ],
      "source": [
        "print(\"ðŸ” Data Validation\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check score ranges\n",
        "max_home_score = matches['homeTeamScore'].max()\n",
        "max_away_score = matches['awayTeamScore'].max()\n",
        "print(f\"   Max home score: {max_home_score}\")\n",
        "print(f\"   Max away score: {max_away_score}\")\n",
        "\n",
        "# Flag anomalous scores (>10 goals)\n",
        "anomalous_mask = (matches['homeTeamScore'] > 10) | (matches['awayTeamScore'] > 10)\n",
        "print(f\"   Matches with score > 10: {anomalous_mask.sum()}\")\n",
        "\n",
        "# Check possession ranges\n",
        "if 'home_possessionPct' in matches.columns:\n",
        "    invalid_poss_mask = (matches['home_possessionPct'] > 100) | (matches['away_possessionPct'] > 100)\n",
        "    print(f\"   Invalid possession (>100%): {invalid_poss_mask.sum()}\")\n",
        "\n",
        "# Validate team relationships\n",
        "same_team_mask = matches['homeTeamId'] == matches['awayTeamId']\n",
        "print(f\"   Matches with same home/away team: {same_team_mask.sum()}\")\n",
        "if same_team_mask.sum() > 0:\n",
        "    matches = matches.loc[~same_team_mask]\n",
        "    print(\"   âš ï¸ Removed invalid matches\")\n",
        "\n",
        "print(\"\\nâœ… Validation complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Select Final Columns (Aligned with ingest_all_data.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Final columns: 48\n",
            "ðŸ“Š Final rows: 57,870\n"
          ]
        }
      ],
      "source": [
        "# Define final column order - aligned with ingest_all_data.py schema\n",
        "FINAL_COLUMNS = [\n",
        "    # Match identifiers\n",
        "    'eventId', 'date', 'leagueId', 'league_code', 'league_name', 'tier',\n",
        "    'venueId', 'attendance', 'seasonType',\n",
        "    \n",
        "    # Teams with full info\n",
        "    'homeTeamId', 'home_team_name', 'home_team_short', 'home_team_logo',\n",
        "    'awayTeamId', 'away_team_name', 'away_team_short', 'away_team_logo',\n",
        "    \n",
        "    # Scores (POST-MATCH - ground truth only)\n",
        "    'homeTeamScore', 'awayTeamScore',\n",
        "    'homeTeamWinner', 'awayTeamWinner',\n",
        "    \n",
        "    # Home team stats (POST-MATCH)\n",
        "    'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget',\n",
        "    'home_wonCorners', 'home_foulsCommitted', 'home_yellowCards', 'home_redCards',\n",
        "    'home_offsides', 'home_saves', 'home_shotPct',\n",
        "    'home_accuratePasses', 'home_totalPasses', 'home_passPct',\n",
        "    \n",
        "    # Away team stats (POST-MATCH)\n",
        "    'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget',\n",
        "    'away_wonCorners', 'away_foulsCommitted', 'away_yellowCards', 'away_redCards',\n",
        "    'away_offsides', 'away_saves', 'away_shotPct',\n",
        "    'away_accuratePasses', 'away_totalPasses', 'away_passPct',\n",
        "    \n",
        "    # Status\n",
        "    'statusId'\n",
        "]\n",
        "\n",
        "# Select columns that exist\n",
        "available_cols = [col for col in FINAL_COLUMNS if col in matches.columns]\n",
        "matches_clean = matches[available_cols].copy()\n",
        "\n",
        "print(f\"ðŸ“‹ Final columns: {len(available_cols)}\")\n",
        "print(f\"ðŸ“Š Final rows: {len(matches_clean):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Export Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved to ../data/processed/matches_base.parquet\n",
            "   File size: 2.76 MB\n",
            "âœ… Saved leagues to ../data/processed/leagues_clean.parquet\n"
          ]
        }
      ],
      "source": [
        "# Save to parquet with compression\n",
        "output_path = PROCESSED_DIR / 'matches_base.parquet'\n",
        "matches_clean.to_parquet(output_path, index=False, compression='snappy')\n",
        "\n",
        "print(f\"âœ… Saved to {output_path}\")\n",
        "print(f\"   File size: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Also save league lookup\n",
        "league_output = PROCESSED_DIR / 'leagues_clean.parquet'\n",
        "league_lookup.to_parquet(league_output, index=False)\n",
        "print(f\"âœ… Saved leagues to {league_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ðŸ“Š CLEANING SUMMARY\n",
            "==================================================\n",
            "   Input fixtures: 67,353\n",
            "   Output matches: 57,870\n",
            "   Tier 1 matches: 2,472\n",
            "   Tier 2 matches: 28,485\n",
            "   Tier 3 matches: 26,405\n",
            "\n",
            "   Stats coverage: 48.8%\n",
            "   Memory usage: 40.03 MB\n"
          ]
        }
      ],
      "source": [
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ðŸ“Š CLEANING SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"   Input fixtures: {len(fixtures):,}\")\n",
        "print(f\"   Output matches: {len(matches_clean):,}\")\n",
        "print(f\"   Tier 1 matches: {len(matches_clean[matches_clean['tier'] == 1]):,}\")\n",
        "print(f\"   Tier 2 matches: {len(matches_clean[matches_clean['tier'] == 2]):,}\")\n",
        "print(f\"   Tier 3 matches: {len(matches_clean[matches_clean['tier'] == 3]):,}\")\n",
        "print(f\"\\n   Stats coverage: {(matches_clean['home_possessionPct'] > 0).sum() / len(matches_clean) * 100:.1f}%\")\n",
        "print(f\"   Memory usage: {matches_clean.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next: 03_feature_engineering.ipynb\n",
        "\n",
        "The clean `matches_base.parquet` is ready for feature engineering:\n",
        "- Rolling form calculations (last 5/10 games) - **PRE-MATCH features**\n",
        "- Home/away specific metrics - **PRE-MATCH features**\n",
        "- Head-to-head history - **PRE-MATCH features**\n",
        "- Pre-match standings context\n",
        "\n",
        "### Important: Pre-match vs Post-match Fields\n",
        "- **Pre-match fields**: Can be used in filter conditions (form, standings, H2H)\n",
        "- **Post-match fields**: Only for ground truth evaluation (scores, actual stats)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "filterbets-UjK3ofNw-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
