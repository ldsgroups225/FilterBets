{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Data Export & Validation\n",
        "\n",
        "Final notebook to validate the enriched data and export for PostgreSQL ingestion.\n",
        "\n",
        "## Key Enhancements\n",
        "- Schema alignment with `ingest_all_data.py` expected format\n",
        "- Proper `features_metadata` JSON structure for database\n",
        "- PRE-MATCH vs POST-MATCH field validation\n",
        "- Data quality checks with detailed reporting\n",
        "- Optimized CSV export for large datasets\n",
        "\n",
        "## Objectives\n",
        "1. Validate data quality and feature coverage\n",
        "2. Check for data leakage (no future data in PRE-MATCH features)\n",
        "3. Export final Parquet files\n",
        "4. Generate PostgreSQL-ready CSVs aligned with `ingest_all_data.py`\n",
        "5. Document final schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Data Export & Validation Pipeline\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "\n",
        "print(\"üìä Data Export & Validation Pipeline\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 57,870 matches\n",
            "   Columns: 107\n",
            "   Memory: 53.87 MB\n"
          ]
        }
      ],
      "source": [
        "# Load enriched matches\n",
        "matches = pd.read_parquet(PROCESSED_DIR / 'matches_enriched.parquet')\n",
        "matches['date'] = pd.to_datetime(matches['date'])\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(matches):,} matches\")\n",
        "print(f\"   Columns: {len(matches.columns)}\")\n",
        "print(f\"   Memory: {matches.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Quality Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Data Quality Report\n",
            "==================================================\n",
            "Total matches: 57,870\n",
            "Total columns: 107\n",
            "\n",
            "Columns with nulls: 55\n",
            "\n",
            "Coverage by Tier:\n",
            "  tier_1: 2,472 matches, 99.6% form coverage\n",
            "  tier_2: 28,485 matches, 98.6% form coverage\n",
            "  tier_3: 26,405 matches, 94.4% form coverage\n"
          ]
        }
      ],
      "source": [
        "def validate_data_quality(df: pd.DataFrame) -> dict:\n",
        "    \"\"\"Comprehensive data quality validation.\"\"\"\n",
        "    report = {\n",
        "        'total_rows': len(df),\n",
        "        'total_columns': len(df.columns),\n",
        "        'null_summary': {},\n",
        "        'coverage_by_tier': {},\n",
        "        'issues': []\n",
        "    }\n",
        "    \n",
        "    # Null analysis\n",
        "    null_counts = df.isnull().sum()\n",
        "    null_pct = (null_counts / len(df) * 100).round(2)\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if null_counts[col] > 0:\n",
        "            report['null_summary'][col] = {\n",
        "                'count': int(null_counts[col]),\n",
        "                'pct': float(null_pct[col])\n",
        "            }\n",
        "    \n",
        "    # Coverage by tier\n",
        "    if 'tier' in df.columns:\n",
        "        for tier in [1, 2, 3]:\n",
        "            tier_df = df[df['tier'] == tier]\n",
        "            if len(tier_df) > 0:\n",
        "                # Check form feature coverage\n",
        "                form_cols = [c for c in df.columns if 'form_' in c]\n",
        "                if form_cols:\n",
        "                    coverage = tier_df[form_cols[0]].notna().mean() * 100\n",
        "                else:\n",
        "                    coverage = 0\n",
        "                report['coverage_by_tier'][f'tier_{tier}'] = {\n",
        "                    'matches': len(tier_df),\n",
        "                    'form_coverage_pct': round(coverage, 1)\n",
        "                }\n",
        "    \n",
        "    return report\n",
        "\n",
        "quality_report = validate_data_quality(matches)\n",
        "print(\"üìä Data Quality Report\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total matches: {quality_report['total_rows']:,}\")\n",
        "print(f\"Total columns: {quality_report['total_columns']}\")\n",
        "print(f\"\\nColumns with nulls: {len(quality_report['null_summary'])}\")\n",
        "print(f\"\\nCoverage by Tier:\")\n",
        "for tier, stats in quality_report['coverage_by_tier'].items():\n",
        "    print(f\"  {tier}: {stats['matches']:,} matches, {stats['form_coverage_pct']}% form coverage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Point-in-Time Validation (No Data Leakage)\n",
        "\n",
        "Verify that PRE-MATCH features don't use future match data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Validating point-in-time correctness...\n",
            "   Early matches null rate: 35.9% (expected: >0 for teams with few games)\n",
            "‚úÖ No obvious data leakage detected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def validate_no_leakage(df: pd.DataFrame, sample_size: int = 100) -> bool:\n",
        "    \"\"\"\n",
        "    Spot check that form features don't include future data.\n",
        "    For PRE-MATCH features, verify they only use past match data.\n",
        "    \"\"\"\n",
        "    print(\"üîç Validating point-in-time correctness...\")\n",
        "    \n",
        "    # Check that early matches have null form features (teams with < min_periods)\n",
        "    df_sorted = df.sort_values('date')\n",
        "    \n",
        "    # First matches for each team should have some null form values\n",
        "    form_cols = [c for c in df.columns if 'form_' in c and not c.startswith('h2h')]\n",
        "    \n",
        "    if not form_cols:\n",
        "        print(\"   ‚ö†Ô∏è No form columns found to validate\")\n",
        "        return True\n",
        "    \n",
        "    # Sample early matches\n",
        "    early_matches = df_sorted.head(1000)\n",
        "    null_rate = early_matches[form_cols].isna().mean().mean()\n",
        "    \n",
        "    print(f\"   Early matches null rate: {null_rate*100:.1f}% (expected: >0 for teams with few games)\")\n",
        "    \n",
        "    # Check that form values are reasonable\n",
        "    issues = 0\n",
        "    \n",
        "    # Form wins/points should be <= n_games\n",
        "    for n in [5, 10]:\n",
        "        win_col = f'home_form_wins_{n}'\n",
        "        if win_col in df.columns:\n",
        "            max_wins = df[win_col].max()\n",
        "            if max_wins > n:\n",
        "                print(f\"   ‚ö†Ô∏è {win_col} has max {max_wins} > {n}\")\n",
        "                issues += 1\n",
        "    \n",
        "    if issues == 0:\n",
        "        print(\"‚úÖ No obvious data leakage detected\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Found {issues} potential issues\")\n",
        "        return False\n",
        "\n",
        "validate_no_leakage(matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define Final Schema (Aligned with ingest_all_data.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Features metadata schema: 43 fields\n",
            "   outcomes: 7 fields\n",
            "   match_stats: 8 fields\n",
            "   home_form_5: 7 fields\n",
            "   away_form_5: 7 fields\n",
            "   home_form_10: 7 fields\n",
            "   away_form_10: 7 fields\n"
          ]
        }
      ],
      "source": [
        "# Define schema aligned with ingest_all_data.py features_metadata structure\n",
        "# These are the fields that will be stored in the JSONB column\n",
        "\n",
        "FEATURES_METADATA_SCHEMA = {\n",
        "    # Ground truth outcomes (POST-MATCH)\n",
        "    'outcomes': [\n",
        "        'total_goals', 'over_1_5', 'over_2_5', 'over_3_5', 'btts',\n",
        "        'home_clean_sheet', 'away_clean_sheet'\n",
        "    ],\n",
        "    \n",
        "    # Match stats (POST-MATCH)\n",
        "    'match_stats': [\n",
        "        'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget', 'home_wonCorners',\n",
        "        'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget', 'away_wonCorners'\n",
        "    ],\n",
        "    \n",
        "    # Form features (PRE-MATCH) - 5 games\n",
        "    'home_form_5': [\n",
        "        'home_form_wins_5', 'home_form_draws_5', 'home_form_losses_5',\n",
        "        'home_form_points_5', 'home_form_goals_scored_5', 'home_form_goals_conceded_5',\n",
        "        'home_form_clean_sheets_5'\n",
        "    ],\n",
        "    'away_form_5': [\n",
        "        'away_form_wins_5', 'away_form_draws_5', 'away_form_losses_5',\n",
        "        'away_form_points_5', 'away_form_goals_scored_5', 'away_form_goals_conceded_5',\n",
        "        'away_form_clean_sheets_5'\n",
        "    ],\n",
        "    \n",
        "    # Form features (PRE-MATCH) - 10 games\n",
        "    'home_form_10': [\n",
        "        'home_form_wins_10', 'home_form_draws_10', 'home_form_losses_10',\n",
        "        'home_form_points_10', 'home_form_goals_scored_10', 'home_form_goals_conceded_10',\n",
        "        'home_form_clean_sheets_10'\n",
        "    ],\n",
        "    'away_form_10': [\n",
        "        'away_form_wins_10', 'away_form_draws_10', 'away_form_losses_10',\n",
        "        'away_form_points_10', 'away_form_goals_scored_10', 'away_form_goals_conceded_10',\n",
        "        'away_form_clean_sheets_10'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Flatten to get all feature columns\n",
        "all_feature_cols = []\n",
        "for category, cols in FEATURES_METADATA_SCHEMA.items():\n",
        "    all_feature_cols.extend(cols)\n",
        "\n",
        "print(f\"üìã Features metadata schema: {len(all_feature_cols)} fields\")\n",
        "for category, cols in FEATURES_METADATA_SCHEMA.items():\n",
        "    print(f\"   {category}: {len(cols)} fields\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prepare PostgreSQL Export\n",
        "\n",
        "Format data to match `ingest_all_data.py` expected structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing PostgreSQL export...\n",
            "   Core columns: 3\n",
            "   Feature columns: 43\n",
            "   Total columns: 107\n"
          ]
        }
      ],
      "source": [
        "def prepare_postgres_export(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Prepare DataFrame for PostgreSQL export.\n",
        "    Matches the expected format in ingest_all_data.py import_processed_matches().\n",
        "    \"\"\"\n",
        "    # Core columns expected by ingest script\n",
        "    core_cols = ['eventId', 'homeTeamScore', 'awayTeamScore']\n",
        "    \n",
        "    # Feature columns to include in features_metadata\n",
        "    feature_cols = [\n",
        "        # Outcomes\n",
        "        'total_goals', 'over_1_5', 'over_2_5', 'over_3_5', 'btts',\n",
        "        'home_clean_sheet', 'away_clean_sheet',\n",
        "        \n",
        "        # Match stats\n",
        "        'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget', 'home_wonCorners',\n",
        "        'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget', 'away_wonCorners',\n",
        "        \n",
        "        # Form 5\n",
        "        'home_form_wins_5', 'home_form_draws_5', 'home_form_losses_5',\n",
        "        'home_form_points_5', 'home_form_goals_scored_5', 'home_form_goals_conceded_5',\n",
        "        'home_form_clean_sheets_5',\n",
        "        'away_form_wins_5', 'away_form_draws_5', 'away_form_losses_5',\n",
        "        'away_form_points_5', 'away_form_goals_scored_5', 'away_form_goals_conceded_5',\n",
        "        'away_form_clean_sheets_5',\n",
        "        \n",
        "        # Form 10\n",
        "        'home_form_wins_10', 'home_form_draws_10', 'home_form_losses_10',\n",
        "        'home_form_points_10', 'home_form_goals_scored_10', 'home_form_goals_conceded_10',\n",
        "        'home_form_clean_sheets_10',\n",
        "        'away_form_wins_10', 'away_form_draws_10', 'away_form_losses_10',\n",
        "        'away_form_points_10', 'away_form_goals_scored_10', 'away_form_goals_conceded_10',\n",
        "        'away_form_clean_sheets_10'\n",
        "    ]\n",
        "    \n",
        "    # Filter to available feature columns\n",
        "    available_features = [c for c in feature_cols if c in df.columns]\n",
        "    \n",
        "    # Select all columns for export\n",
        "    export_cols = core_cols + available_features + [\n",
        "        c for c in df.columns if c not in core_cols + available_features\n",
        "    ]\n",
        "    export_cols = [c for c in export_cols if c in df.columns]\n",
        "    \n",
        "    result = df[export_cols].copy()\n",
        "    \n",
        "    print(f\"   Core columns: {len(core_cols)}\")\n",
        "    print(f\"   Feature columns: {len(available_features)}\")\n",
        "    print(f\"   Total columns: {len(export_cols)}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"Preparing PostgreSQL export...\")\n",
        "postgres_df = prepare_postgres_export(matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Export Final Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Final schema: 78 columns\n",
            "   Form features: 50\n"
          ]
        }
      ],
      "source": [
        "# Select final columns for Parquet export\n",
        "FINAL_SCHEMA = {\n",
        "    'identifiers': ['eventId', 'date', 'leagueId', 'league_code', 'league_name', 'tier'],\n",
        "    'teams': ['homeTeamId', 'home_team_name', 'awayTeamId', 'away_team_name'],\n",
        "    'scores': ['homeTeamScore', 'awayTeamScore'],\n",
        "    'outcomes': ['result', 'total_goals', 'over_1_5', 'over_2_5', 'over_3_5', 'btts',\n",
        "                 'home_clean_sheet', 'away_clean_sheet'],\n",
        "    'match_stats': ['home_possessionPct', 'home_totalShots', 'home_shotsOnTarget', \n",
        "                    'home_wonCorners', 'away_possessionPct', 'away_totalShots',\n",
        "                    'away_shotsOnTarget', 'away_wonCorners']\n",
        "}\n",
        "\n",
        "# Get all available columns\n",
        "available_cols = []\n",
        "for category, cols in FINAL_SCHEMA.items():\n",
        "    for col in cols:\n",
        "        if col in matches.columns:\n",
        "            available_cols.append(col)\n",
        "\n",
        "# Add form features\n",
        "form_cols = sorted([c for c in matches.columns if 'form_' in c or '_avg_' in c])\n",
        "available_cols.extend(form_cols)\n",
        "\n",
        "# Remove duplicates while preserving order\n",
        "seen = set()\n",
        "final_cols = []\n",
        "for col in available_cols:\n",
        "    if col not in seen:\n",
        "        seen.add(col)\n",
        "        final_cols.append(col)\n",
        "\n",
        "print(f\"üìã Final schema: {len(final_cols)} columns\")\n",
        "print(f\"   Form features: {len(form_cols)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Exported ../data/processed/matches_final.parquet\n",
            "   Size: 3.59 MB\n",
            "‚úÖ Exported ../data/processed/matches_for_postgres.csv\n",
            "   Size: 31.98 MB\n"
          ]
        }
      ],
      "source": [
        "# Select final columns\n",
        "final_matches = matches[[c for c in final_cols if c in matches.columns]].copy()\n",
        "\n",
        "# Export Parquet (optimized for analysis)\n",
        "parquet_path = PROCESSED_DIR / 'matches_final.parquet'\n",
        "final_matches.to_parquet(parquet_path, index=False, compression='snappy')\n",
        "print(f\"‚úÖ Exported {parquet_path}\")\n",
        "print(f\"   Size: {parquet_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Export CSV for PostgreSQL - use postgres_df which has all features\n",
        "csv_path = PROCESSED_DIR / 'matches_for_postgres.csv'\n",
        "postgres_df.to_csv(csv_path, index=False)\n",
        "print(f\"‚úÖ Exported {csv_path}\")\n",
        "print(f\"   Size: {csv_path.stat().st_size / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generate Schema Documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved schema documentation to ../data/processed/schema_documentation.json\n"
          ]
        }
      ],
      "source": [
        "# Generate comprehensive schema documentation\n",
        "schema_doc = {\n",
        "    'generated_at': datetime.now().isoformat(),\n",
        "    'total_matches': len(final_matches),\n",
        "    'date_range': {\n",
        "        'min': str(final_matches['date'].min()),\n",
        "        'max': str(final_matches['date'].max())\n",
        "    },\n",
        "    'columns': {},\n",
        "    'tier_distribution': final_matches['tier'].value_counts().to_dict() if 'tier' in final_matches.columns else {},\n",
        "    'features_metadata_schema': FEATURES_METADATA_SCHEMA,\n",
        "    'pre_match_fields': [\n",
        "        c for c in final_matches.columns if 'form_' in c or '_avg_' in c or 'h2h_' in c\n",
        "    ],\n",
        "    'post_match_fields': [\n",
        "        'homeTeamScore', 'awayTeamScore', 'result', 'total_goals',\n",
        "        'over_1_5', 'over_2_5', 'over_3_5', 'btts',\n",
        "        'home_clean_sheet', 'away_clean_sheet',\n",
        "        'home_possessionPct', 'home_totalShots', 'home_shotsOnTarget', 'home_wonCorners',\n",
        "        'away_possessionPct', 'away_totalShots', 'away_shotsOnTarget', 'away_wonCorners'\n",
        "    ]\n",
        "}\n",
        "\n",
        "for col in final_matches.columns:\n",
        "    col_data = final_matches[col]\n",
        "    schema_doc['columns'][col] = {\n",
        "        'dtype': str(col_data.dtype),\n",
        "        'null_count': int(col_data.isnull().sum()),\n",
        "        'sample_values': col_data.dropna().head(3).tolist()[:3] if len(col_data.dropna()) > 0 else []\n",
        "    }\n",
        "\n",
        "# Save schema\n",
        "schema_path = PROCESSED_DIR / 'schema_documentation.json'\n",
        "with open(schema_path, 'w') as f:\n",
        "    json.dump(schema_doc, f, indent=2, default=str)\n",
        "print(f\"‚úÖ Saved schema documentation to {schema_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved quality report to ../data/processed/data_quality_report.json\n"
          ]
        }
      ],
      "source": [
        "# Save data quality report\n",
        "quality_report['generated_at'] = datetime.now().isoformat()\n",
        "quality_path = PROCESSED_DIR / 'data_quality_report.json'\n",
        "with open(quality_path, 'w') as f:\n",
        "    json.dump(quality_report, f, indent=2, default=str)\n",
        "print(f\"‚úÖ Saved quality report to {quality_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìä FINAL DATA SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total matches: 57,870\n",
            "Date range: 2024-01-01 to 2025-12-15\n",
            "Columns: 78\n",
            "\n",
            "Matches by Tier:\n",
            "  Tier 1: 2,472 (4.3%)\n",
            "  Tier 2: 28,485 (49.2%)\n",
            "  Tier 3: 26,405 (45.6%)\n",
            "\n",
            "Result Distribution:\n",
            "  H: 26,113 (45.1%)\n",
            "  A: 17,271 (29.8%)\n",
            "  D: 14,486 (25.0%)\n",
            "\n",
            "Over 2.5 Goals: 49.3%\n",
            "BTTS: 49.3%\n",
            "\n",
            "PRE-MATCH features: 50\n",
            "POST-MATCH fields: 5\n",
            "\n",
            "‚úÖ Data preparation complete!\n",
            "   Output files in: ../data/processed\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä FINAL DATA SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal matches: {len(final_matches):,}\")\n",
        "print(f\"Date range: {final_matches['date'].min().date()} to {final_matches['date'].max().date()}\")\n",
        "print(f\"Columns: {len(final_matches.columns)}\")\n",
        "\n",
        "if 'tier' in final_matches.columns:\n",
        "    print(f\"\\nMatches by Tier:\")\n",
        "    for tier in sorted(final_matches['tier'].dropna().unique()):\n",
        "        count = len(final_matches[final_matches['tier'] == tier])\n",
        "        print(f\"  Tier {int(tier)}: {count:,} ({count/len(final_matches)*100:.1f}%)\")\n",
        "\n",
        "if 'result' in final_matches.columns:\n",
        "    print(f\"\\nResult Distribution:\")\n",
        "    for result, count in final_matches['result'].value_counts().items():\n",
        "        print(f\"  {result}: {count:,} ({count/len(final_matches)*100:.1f}%)\")\n",
        "\n",
        "if 'over_2_5' in final_matches.columns:\n",
        "    print(f\"\\nOver 2.5 Goals: {final_matches['over_2_5'].mean()*100:.1f}%\")\n",
        "if 'btts' in final_matches.columns:\n",
        "    print(f\"BTTS: {final_matches['btts'].mean()*100:.1f}%\")\n",
        "\n",
        "# PRE-MATCH feature summary\n",
        "pre_match = [c for c in final_matches.columns if 'form_' in c or '_avg_' in c]\n",
        "post_match = ['homeTeamScore', 'awayTeamScore', 'result', 'total_goals', 'btts']\n",
        "print(f\"\\nPRE-MATCH features: {len(pre_match)}\")\n",
        "print(f\"POST-MATCH fields: {len([c for c in post_match if c in final_matches.columns])}\")\n",
        "\n",
        "print(\"\\n‚úÖ Data preparation complete!\")\n",
        "print(f\"   Output files in: {PROCESSED_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output Files\n",
        "\n",
        "### Generated Files:\n",
        "- `matches_final.parquet` - Main backtesting dataset (Parquet format)\n",
        "- `matches_for_postgres.csv` - PostgreSQL import ready (aligned with `ingest_all_data.py`)\n",
        "- `schema_documentation.json` - Column definitions, stats, and PRE/POST-MATCH classification\n",
        "- `data_quality_report.json` - Data quality metrics\n",
        "- `team_history.parquet` - Team match history with rolling features\n",
        "- `leagues_clean.parquet` - League metadata with tiers\n",
        "\n",
        "### Next Steps:\n",
        "1. **Ingest to PostgreSQL**: Run `poetry run python backend/scripts/ingest_all_data.py`\n",
        "2. **Backtesting**: Load `matches_final.parquet` for filter evaluation\n",
        "3. **Filter Creation**: Use PRE-MATCH features only for filter conditions\n",
        "\n",
        "### Important Notes:\n",
        "- **PRE-MATCH features** (form, H2H, rolling stats): Safe for filter conditions\n",
        "- **POST-MATCH features** (scores, actual stats): Ground truth for backtesting evaluation only\n",
        "- Using POST-MATCH features in filter conditions causes **look-ahead bias**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "filterbets-UjK3ofNw-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
