# BetMines Analysis

## Q: What is BetMines?

A: BetMines is a platform offering free football statistics and predictions. It aims to help users make informed bets with confidence.

## Q: What are the main features of BetMines?

A: BetMines provides:

- **Free Football Predictions:** Daily tips for major leagues like Ligue 1, Premier League, Serie A, La Liga, and more.
- **In-depth Statistics:** Detailed stats for over 150 leagues worldwide, including national and international cups.
- **AI-Powered Predictions:** Predictions are generated by a proprietary artificial intelligence algorithm.
- **A Variety of Tools:** Including match analysis, advanced filters, and the "BetMines Machine".

## Q: How are the predictions made?

A: The predictions are generated by a sophisticated algorithm based on statistical football data from the last 20 years. It uses a Bayesian model to measure the probability of various match events. The algorithm is constantly updated to improve its accuracy.

## Q: What data is considered for the predictions?

A: The algorithm takes into account a wide range of data, including:

- Past results of the teams.
- Recent team form.
- Head-to-head match history.
- Home and away performance.
- Statistical data from the relevant league.
- Information about unavailable players.

## Q: What kind of tools are available on the platform?

A: The platform offers several tools to assist users:

- **Matchs:** A calendar of football matches.
- **Analyse des matchs:** In-depth match analysis.
- **Filtres avancÃ©s:** Advanced filters to sift through matches based on various statistical criteria.
- **BetMines Machine:** A tool to generate predictions based on user-selected criteria.
- **Live scanner:** A premium tool for live match scanning.
- **Scanner PrÃ©-Match:** A premium pre-match scanning tool.
- **Value bet bot:** A premium bot to find value bets.

## Q: Is there a premium service?

A: Yes, BetMines offers a Premium service that unlocks more data and advanced tools like the Live scanner, Pre-Match scanner, and Value bet bot to enhance the betting experience.

## Q: How does the Pre-Match Scanner work?

A: The BetMines Pre-Match Scanner is a tool that automates the analysis of all scheduled football matches. Here's a breakdown of its functionality:

- **Automated Analysis:** It analyzes all upcoming football matches based on user-defined criteria.
- **Customizable Strategies:** Users can create personalized strategies by selecting from a wide range of criteria, including odds, probabilities, and dozens of statistics (e.g., wins, losses, draws, average goals, corner kicks).
- **Telegram Notifications:** When a match meets the user's specified criteria, a notification is sent via Telegram, ensuring users don't miss betting opportunities.
- **Backtesting:** A powerful feature that allows users to test their strategies against historical data to evaluate their effectiveness over time. This helps in refining strategies without waiting for future matches.
- **Data Export:** The service provides an Excel file containing the analyzed match data, allowing for deeper, custom analysis, and the creation of charts and reports.
- **Time-Saving:** It automates the heavy lifting of analyzing matches, saving users time and effort.

## Q: I want to build "FilterBets" using a Kaggle dataset, Jupyter Notebooks, FastAPI, PostgreSQL, and TanStack. What's missing from my stack?

A: Your chosen tech stack provides a strong foundation. However, to replicate the full functionality of a service like BetMines, especially its real-time features and robust operation, here are the key missing components:

- **Real-time Data Source:** The Kaggle dataset is excellent for historical data and backtesting, but it's not live. To power a "Live Scanner" and provide up-to-the-minute odds and match events, you will need to subscribe to a **real-time sports data API**.

- **Task Queue & Scheduler:** To handle background tasks efficiently without blocking the backend, you need a task queue. This is critical for:
  - Sending Telegram notifications instantly.
  - Running scheduled jobs (e.g., daily data ingestion from your Kaggle source, running pre-match analysis).
  - **Tech to consider:** **Celery** with **Redis** or **RabbitMQ** is the industry standard for Python applications.

- **Frontend Framework:** "TanStack" is a collection of powerful libraries, but not a complete framework. You need to choose a primary JavaScript framework to build your user interface, which will then use the TanStack libraries for state management, data fetching, and tables.
  - **Tech to consider:** **React**, **Vue**, or **Angular**. Given you're using TanStack, React is a very common and well-supported choice (often referred to as the "TanStack").

- **Caching Layer:** To ensure your application is fast and can handle many users without overloading the database, a caching layer is essential. It can store frequently accessed data (like popular match stats or recent results) in memory.
  - **Tech to consider:** **Redis** is an excellent choice and can also serve as the message broker for Celery.

- **Deployment & Infrastructure (DevOps):** A plan for how to deploy and host your application is crucial for a real-world service.
  - **Containerization:** **Docker** should be used to package your FastAPI application, PostgreSQL database, and other services into portable containers. **Docker Compose** is great for managing this in a development environment.
  - **Hosting:** You'll need a server to run your application. Cloud platforms like **AWS**, **Google Cloud Platform (GCP)**, or **Microsoft Azure** offer the flexibility to host your containers.
  - **CI/CD Pipeline:** To automate testing and deployment, setting up a CI/CD pipeline is a best practice.
    - **Tech to consider:** **GitHub Actions** or **GitLab CI/CD**.

## Q: Can you provide personas for the "FilterBets" project?

A: Certainly. Here are four key personas representing the developer building the data pipeline and different types of end-users for the platform.

---

### Persona 1: Alex, the Data Engineer (Dev Persona)

**Background:**

- **Role:** Data Engineer / Backend Developer
- **Age:** 29
- **Tech-Savviness:** High. Proficient in Python, SQL, and comfortable with data manipulation libraries like Pandas.
- **Goal:** To build a reliable and automated data pipeline that feeds the "FilterBets" application with clean, structured, and up-to-date historical football data.

**Pain Points:**

- "The Kaggle dataset is great, but it's a collection of raw CSV files. Manually cleaning and relating them is time-consuming and error-prone."
- "I need to make sure the data I load into the database is pristine, otherwise the backtesting results will be meaningless."
- "Running data import scripts manually is not a long-term solution. I need a 'set it and forget it' process."

**Ideal Workflow for Managing Historical Data:**

1. **Exploration & Prototyping (Jupyter Notebook):**
    - Alex starts by firing up a Jupyter Notebook to interactively explore the CSVs from the Kaggle dataset.
    - He uses **Pandas** to load `fixtures.csv`, `teamStats.csv`, and `leagues.csv`.
    - He prototypes the logic for merging these datasets, cleaning data (e.g., handling missing odds, standardizing date formats), and transforming it into the schema required by the application.

2. **Scripting & Automation (Python/FastAPI):**
    - Once the logic is proven in the notebook, Alex converts it into a standalone Python script.
    - This script uses **SQLAlchemy** to define the table models that map to the PostgreSQL database schema.
    - It includes functions to:
        1. Download and unzip the dataset.
        2. Read and process each CSV into a Pandas DataFrame.
        3. Perform the cleaning and transformation operations.
        4. Use SQLAlchemy's ORM or Core to efficiently bulk-insert the cleaned data into the PostgreSQL database, ensuring data integrity and handling relationships between tables.

3. **Making it Ready for Backtesting:**
    - Alex creates an API endpoint in **FastAPI** (e.g., `/data/ingest`) that triggers this data processing script.
    - He then sets up a `cron` job (or a more advanced scheduler like Celery Beat) to call this endpoint on a daily basis, ensuring the historical data stays fresh.
    - The final result is a well-structured database that the backtesting engine can query efficiently to test user-defined filter strategies.

---

### Persona 2: Chloe, the Strategic Bettor (Core User Persona)

**Background:**

- **Role:** Hobbyist sports bettor with a full-time job.
- **Age:** 34
- **Tech-Savviness:** Medium. Comfortable with web applications and uses Telegram daily. Not a programmer.
- **Goal:** To find and validate profitable betting strategies without spending hours manually researching stats. She wants to be automatically notified of high-probability opportunities.

**Pain Points:**

- "There's too much data out there. I feel like I'm drowning in stats and can't find a real edge."
- "I have betting ideas, but I have no way of knowing if they would have actually worked in the past."
- "I've missed good bets because I wasn't at my computer to see the opportunity."

**Ideal Workflow for Using "FilterBets":**

1. **Filter Creation & Rule-Setting:**
    - Chloe logs into the "FilterBets" web application. She navigates to the "Pre-Match Scanner" and clicks "Create New Filter."
    - Using a user-friendly form, she builds her strategy. She names it "High-Scoring Home Favorites."
    - She adds a series of rules:
        - `League` is one of `['Premier League', 'La Liga']`
        - `Home Team Win Probability (%)` is greater than `65`
        - `Home Team Avg Goals (Last 6 Games)` is greater than or equal to `2.5`
        - `Away Team Avg Goals Conceded (Last 6 Games)` is greater than or equal to `1.5`

2. **Connecting Notifications:**
    - In her profile settings, she sees a "Connect Telegram" button.
    - She clicks it and receives a unique code and a link to the FilterBets Telegram bot. She messages the code to the bot, which confirms the link between her app account and Telegram.

3. **Backtesting the Strategy:**
    - After saving her filter, she clicks the "Backtest" button.
    - The application queries the historical dataset in the backend.
    - Within seconds, the UI (built with TanStack) updates to show the results:
        - "Strategy 'High-Scoring Home Favorites' matched **82 games** last season."
        - "Net Profit if betting $10 on each: **+$420.50**"
        - "Win Rate: **71%**"
        - A table shows all the historical matches that would have matched her filter, allowing her to see where the strategy succeeded or failed.

4. **Activation and Receiving Alerts:**
    - Pleased with the results, Chloe toggles an "Activate Alerts" switch for her filter.
    - The next day, she receives a Telegram notification: *"FilterBets Alert: Your filter 'High-Scoring Home Favorites' has a new match: Manchester United vs. Everton."*
    - The alert includes key stats and a direct link to the match on her preferred betting site, allowing her to place a well-researched bet in minutes.

---

### Persona 3: David, the Professional Analyst (Power User)

**Background:**

- **Role:** Freelance Data Scientist, contributes to sports analytics blogs.
- **Age:** 38
- **Tech-Savviness:** Very High. Expert in Python (Pandas, Scikit-learn), R, SQL, and API integration.
- **Goal:** To access high-quality, pre-processed football data to build and test his own predictive models. He wants to find unique statistical angles that standard platforms don't offer.

**Pain Points:**

- "Most betting sites have basic stats. I spend 80% of my time just collecting and cleaning data instead of modeling."
- "I want to test complex, multi-variable hypotheses that simple web interfaces don't support."
- "Exporting data in a usable format is often impossible. I hate being stuck inside a 'walled garden'."

**Ideal Workflow:**

1. **Data Acquisition:** David subscribes to the "FilterBets" Pro tier, which grants him API access.
2. **API Integration:** He writes a Python script to programmatically pull large amounts of historical data directly from the "FilterBets" API. He filters for specific leagues and a wide range of stats (e.g., player-level data, expected goals (xG), card statistics) over multiple seasons.
3. **Custom Modeling:** He loads the data into his local environment (Jupyter, VS Code) and uses it to train his own custom machine learning models (e.g., a Gradient Boosting model to predict the probability of a draw).
4. **Strategy Validation:** Instead of using the UI's backtester, he uses the "FilterBets" API to pull fresh, daily odds. He runs these odds against his model's predictions to identify "value bets" where his model's assessed probability is higher than the one implied by the bookmaker's odds.
5. **Content Creation:** He uses the insights and the performance of his models to write articles for sports analytics blogs, using "FilterBets" as his primary data source, which he credits.

---

### Persona 4: Maria, the Casual Fan (Social User)

**Background:**

- **Role:** Marketing Manager, big football fan.
- **Age:** 26
- **Tech-Savviness:** Low to Medium. Very active on social media (Instagram, Telegram) and comfortable with modern mobile apps.
- **Goal:** To make watching the weekend's matches more exciting by placing small, informed bets. She wants quick, reliable tips without getting bogged down in complex charts.

**Pain Points:**

- "I love watching football, but I don't have time to study statistics for hours."
- "All the betting sites look so complicated and intimidating."
- "I want to know what bets are popular or what the 'experts' are backing."

**Ideal Workflow:**

1. **Discovering Tips:** It's Saturday morning. Maria opens the "FilterBets" app on her phone. She skips the "Create Filter" section and goes straight to a "Trending Filters" or "Popular Bets" tab.
2. **Social Proof:** The app shows her a simple card: "ğŸ”¥ **Today's Most Popular Filter: Home Team Over 1.5 Goals**". The card shows this filter has a 75% historical win rate and has been used by 500 other users today.
3. **One-Click Action:** She taps on the card. The app shows the 3 matches today that fit this popular filter. Beside each match is a simple "Track this Bet" button. She taps it for the two matches she's interested in.
4. **Effortless Notifications:** Because she's tracking the bets, her "FilterBets" app automatically sends her a push notification 15 minutes before each match starts.
5. **Sharing with Friends:** Her first bet wins. The app sends a celebratory notification. With one tap, she can share a "bragging rights" graphic to her friends' Telegram group: *"Just won with FilterBets! âš½ï¸ğŸ’° #FilterBetsWinner"*.

---

## Q: What is the recommended final tech stack for FilterBets?

A: Based on the analysis, here's the complete recommended stack:

| Layer | Technology | Purpose |
| ------- | ------------ | --------- |
| **Frontend** | React 18+ with TypeScript | UI Framework |
| **State/Data** | TanStack Query + TanStack Table | Data fetching, caching, tables |
| **Styling** | Tailwind CSS + shadcn/ui | Rapid UI development |
| **Backend** | FastAPI (Python 3.11+) | REST API + WebSocket support |
| **ORM** | SQLAlchemy 2.0 + Alembic | Database models + migrations |
| **Database** | PostgreSQL 15+ | Primary data store |
| **Cache/Broker** | Redis | Caching + Celery message broker |
| **Task Queue** | Celery + Celery Beat | Background jobs + scheduling |
| **Notifications** | python-telegram-bot | Telegram alerts |
| **Data Analysis** | Jupyter + Pandas + NumPy | Prototyping + data exploration |
| **ML (optional)** | Scikit-learn | Prediction models |
| **Auth** | JWT + OAuth2 (FastAPI) | User authentication |
| **Containerization** | Docker + Docker Compose | Development & deployment |
| **CI/CD** | GitHub Actions | Automated testing & deployment |

---

## Q: What is the database schema for FilterBets?

A: Here's the core database schema design:

```sql
-- Core entities
CREATE TABLE leagues (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    country VARCHAR(100),
    api_id VARCHAR(50) UNIQUE,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE teams (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    league_id INTEGER REFERENCES leagues(id),
    api_id VARCHAR(50) UNIQUE,
    logo_url VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE fixtures (
    id SERIAL PRIMARY KEY,
    league_id INTEGER REFERENCES leagues(id),
    home_team_id INTEGER REFERENCES teams(id),
    away_team_id INTEGER REFERENCES teams(id),
    match_date TIMESTAMP NOT NULL,
    status VARCHAR(20) DEFAULT 'scheduled', -- scheduled, live, finished, postponed
    home_score INTEGER,
    away_score INTEGER,
    home_ht_score INTEGER,
    away_ht_score INTEGER,
    api_id VARCHAR(50) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE odds (
    id SERIAL PRIMARY KEY,
    fixture_id INTEGER REFERENCES fixtures(id),
    bookmaker VARCHAR(50),
    home_win DECIMAL(5,2),
    draw DECIMAL(5,2),
    away_win DECIMAL(5,2),
    over_2_5 DECIMAL(5,2),
    under_2_5 DECIMAL(5,2),
    btts_yes DECIMAL(5,2),
    btts_no DECIMAL(5,2),
    recorded_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE team_stats (
    id SERIAL PRIMARY KEY,
    team_id INTEGER REFERENCES teams(id),
    season VARCHAR(10),
    matches_played INTEGER DEFAULT 0,
    wins INTEGER DEFAULT 0,
    draws INTEGER DEFAULT 0,
    losses INTEGER DEFAULT 0,
    goals_scored INTEGER DEFAULT 0,
    goals_conceded INTEGER DEFAULT 0,
    home_wins INTEGER DEFAULT 0,
    home_draws INTEGER DEFAULT 0,
    home_losses INTEGER DEFAULT 0,
    away_wins INTEGER DEFAULT 0,
    away_draws INTEGER DEFAULT 0,
    away_losses INTEGER DEFAULT 0,
    avg_goals_scored DECIMAL(4,2),
    avg_goals_conceded DECIMAL(4,2),
    clean_sheets INTEGER DEFAULT 0,
    failed_to_score INTEGER DEFAULT 0,
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(team_id, season)
);

-- User & Filter system
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    telegram_chat_id VARCHAR(50),
    telegram_verified BOOLEAN DEFAULT false,
    subscription_tier VARCHAR(20) DEFAULT 'free', -- free, premium, pro
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE filters (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    name VARCHAR(100) NOT NULL,
    description TEXT,
    rules JSONB NOT NULL, -- Stores filter criteria as JSON
    is_active BOOLEAN DEFAULT true,
    alerts_enabled BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE filter_matches (
    id SERIAL PRIMARY KEY,
    filter_id INTEGER REFERENCES filters(id),
    fixture_id INTEGER REFERENCES fixtures(id),
    matched_at TIMESTAMP DEFAULT NOW(),
    notification_sent BOOLEAN DEFAULT false,
    bet_result VARCHAR(20), -- win, loss, push, pending
    UNIQUE(filter_id, fixture_id)
);

CREATE TABLE backtest_results (
    id SERIAL PRIMARY KEY,
    filter_id INTEGER REFERENCES filters(id),
    season VARCHAR(10),
    total_matches INTEGER,
    wins INTEGER,
    losses INTEGER,
    pushes INTEGER,
    roi_percentage DECIMAL(6,2),
    avg_odds DECIMAL(5,2),
    run_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_fixtures_date ON fixtures(match_date);
CREATE INDEX idx_fixtures_status ON fixtures(status);
CREATE INDEX idx_odds_fixture ON odds(fixture_id);
CREATE INDEX idx_team_stats_team_season ON team_stats(team_id, season);
CREATE INDEX idx_filters_user ON filters(user_id);
CREATE INDEX idx_filter_matches_filter ON filter_matches(filter_id);
```

---

## Q: What are the core API endpoints for FilterBets?

A: Here's the API structure organized by domain:

### Authentication

| Method | Endpoint | Description |
| -------- | ---------- | ------------- |
| POST | `/auth/register` | Create new user account |
| POST | `/auth/login` | Login and get JWT token |
| POST | `/auth/refresh` | Refresh access token |
| GET | `/auth/me` | Get current user profile |
| POST | `/auth/telegram/link` | Generate Telegram linking code |
| POST | `/auth/telegram/verify` | Verify Telegram connection |

### Matches & Data

| Method | Endpoint | Description |
| -------- | ---------- | ------------- |
| GET | `/leagues` | List all available leagues |
| GET | `/leagues/{id}/teams` | Get teams in a league |
| GET | `/fixtures` | List fixtures with filters (date, league, status) |
| GET | `/fixtures/{id}` | Get fixture details with stats & odds |
| GET | `/fixtures/today` | Get today's matches |
| GET | `/fixtures/upcoming` | Get upcoming matches (next 7 days) |
| GET | `/teams/{id}` | Get team details |
| GET | `/teams/{id}/stats` | Get team statistics |
| GET | `/teams/{id}/form` | Get team's recent form (last N games) |
| GET | `/head-to-head/{team1_id}/{team2_id}` | Get H2H history |

### Filters & Scanner

| Method | Endpoint | Description |
| -------- | ---------- | ------------- |
| GET | `/filters` | List user's filters |
| POST | `/filters` | Create new filter |
| GET | `/filters/{id}` | Get filter details |
| PUT | `/filters/{id}` | Update filter |
| DELETE | `/filters/{id}` | Delete filter |
| POST | `/filters/{id}/toggle-alerts` | Enable/disable alerts |
| GET | `/filters/{id}/matches` | Get matches that fit this filter |
| POST | `/filters/{id}/backtest` | Run backtest on historical data |
| GET | `/scanner/pre-match` | Run all active filters on upcoming matches |

### Premium Features

| Method | Endpoint | Description |
| -------- | ---------- | ------------- |
| GET | `/scanner/live` | Live match scanner (Premium) |
| GET | `/value-bets` | Get current value bet opportunities (Premium) |
| GET | `/export/matches` | Export matches to Excel (Premium) |
| GET | `/api/v1/data/*` | Full API access for Pro users |

### Social Features

| Method | Endpoint | Description |
| -------- | ---------- | ------------- |
| GET | `/filters/trending` | Get popular public filters |
| POST | `/filters/{id}/share` | Make filter public |
| GET | `/filters/{id}/stats` | Get filter usage statistics |

---

## Q: What are the key filter criteria available?

A: Users can build filters using these criteria categories:

### Match Context

- League selection (multi-select)
- Match date range
- Home/Away team selection
- Match importance (league position implications)

### Odds-Based Criteria

- Home win odds (range)
- Draw odds (range)
- Away win odds (range)
- Over/Under 2.5 goals odds
- BTTS (Both Teams To Score) odds

### Probability Criteria (AI-calculated)

- Home win probability (%)
- Draw probability (%)
- Away win probability (%)
- Over 2.5 goals probability (%)
- BTTS probability (%)

### Team Form Statistics

- Last N games: wins, draws, losses
- Last N games: goals scored/conceded average
- Last N games: clean sheets
- Last N games: failed to score
- Current league position
- Points from last N games

### Home/Away Specific

- Home team home record (W-D-L)
- Away team away record (W-D-L)
- Home team home goals average
- Away team away goals average

### Head-to-Head

- H2H last N meetings result
- H2H goals average
- H2H home team win rate

### Advanced (Premium)

- Expected Goals (xG) metrics
- Corner kick statistics
- Card statistics (yellow/red)
- Possession averages
- Shots on target averages

---

## Q: How should the backtesting engine work?

A: The backtesting engine is critical for validating filter strategies. Here's the design:

### Core Algorithm

```python
def run_backtest(filter_rules: dict, seasons: list[str]) -> BacktestResult:
    """
    1. Parse filter rules into SQL/ORM query conditions
    2. Query historical fixtures matching the criteria
    3. For each matched fixture:
       - Determine if the bet would have won based on actual result
       - Calculate profit/loss using historical odds
    4. Aggregate results and calculate metrics
    """
    
    matched_fixtures = query_historical_fixtures(filter_rules, seasons)
    
    results = []
    for fixture in matched_fixtures:
        bet_outcome = evaluate_bet_outcome(fixture, filter_rules.bet_type)
        profit_loss = calculate_profit(fixture.odds, bet_outcome, stake=1.0)
        results.append({
            'fixture': fixture,
            'outcome': bet_outcome,
            'profit_loss': profit_loss
        })
    
    return BacktestResult(
        total_matches=len(results),
        wins=sum(1 for r in results if r['outcome'] == 'win'),
        losses=sum(1 for r in results if r['outcome'] == 'loss'),
        total_profit=sum(r['profit_loss'] for r in results),
        roi_percentage=calculate_roi(results),
        avg_odds=calculate_avg_odds(matched_fixtures),
        longest_winning_streak=calculate_streak(results, 'win'),
        longest_losing_streak=calculate_streak(results, 'loss'),
        monthly_breakdown=group_by_month(results)
    )
```

### Backtest Metrics Returned

- Total matches analyzed
- Win/Loss/Push count
- Win rate (%)
- Total profit/loss (assuming flat stake)
- ROI percentage
- Average odds
- Longest winning/losing streak
- Monthly performance breakdown
- Drawdown analysis

### Performance Considerations

- Pre-compute and cache team statistics per season
- Use database indexes on date, league, team columns
- Limit backtest to reasonable date ranges (max 5 seasons)
- Run heavy backtests as Celery background tasks

---

## Q: How should Telegram notifications be implemented?

A: Here's the notification system architecture:

### Telegram Bot Setup

```python
# bot/telegram_bot.py
from telegram import Update, Bot
from telegram.ext import Application, CommandHandler, MessageHandler

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

async def start_command(update: Update, context):
    """Handle /start command - show welcome and linking instructions"""
    await update.message.reply_text(
        "Welcome to FilterBets! ğŸ¯\n\n"
        "To link your account, use /link <your_code>\n"
        "Get your code from the FilterBets app settings."
    )

async def link_command(update: Update, context):
    """Handle /link <code> - verify and link Telegram to user account"""
    if not context.args:
        await update.message.reply_text("Usage: /link <your_code>")
        return
    
    code = context.args[0]
    chat_id = update.effective_chat.id
    
    # Verify code and link account (call your API)
    success = await verify_telegram_link(code, chat_id)
    
    if success:
        await update.message.reply_text("âœ… Account linked successfully!")
    else:
        await update.message.reply_text("âŒ Invalid or expired code.")
```

### Notification Service (Celery Task)

```python
# tasks/notifications.py
from celery import shared_task
from telegram import Bot

@shared_task
def send_filter_alert(user_telegram_id: str, filter_name: str, fixture_data: dict):
    """Send match alert to user via Telegram"""
    bot = Bot(token=TELEGRAM_BOT_TOKEN)
    
    message = f"""
ğŸ¯ *FilterBets Alert*

Your filter *"{filter_name}"* matched a new game!

âš½ *{fixture_data['home_team']} vs {fixture_data['away_team']}*
ğŸ† {fixture_data['league']}
ğŸ“… {fixture_data['match_date']}

ğŸ“Š *Key Stats:*
â€¢ Home win prob: {fixture_data['home_prob']}%
â€¢ Over 2.5 prob: {fixture_data['over_prob']}%

ğŸ’° *Odds:* {fixture_data['odds']}

[View Match Details]({fixture_data['match_url']})
    """
    
    bot.send_message(
        chat_id=user_telegram_id,
        text=message,
        parse_mode='Markdown'
    )

@shared_task
def run_pre_match_scanner():
    """Scheduled task: scan upcoming matches against all active filters"""
    upcoming_fixtures = get_upcoming_fixtures(hours=24)
    active_filters = get_all_active_filters_with_alerts()
    
    for filter in active_filters:
        matching_fixtures = apply_filter(filter.rules, upcoming_fixtures)
        for fixture in matching_fixtures:
            # Avoid duplicate notifications
            if not already_notified(filter.id, fixture.id):
                send_filter_alert.delay(
                    filter.user.telegram_chat_id,
                    filter.name,
                    serialize_fixture(fixture)
                )
                mark_as_notified(filter.id, fixture.id)
```

### Celery Beat Schedule

```python
# celery_config.py
from celery.schedules import crontab

beat_schedule = {
    'pre-match-scanner-morning': {
        'task': 'tasks.notifications.run_pre_match_scanner',
        'schedule': crontab(hour=8, minute=0),  # Run at 8 AM daily
    },
    'pre-match-scanner-afternoon': {
        'task': 'tasks.notifications.run_pre_match_scanner',
        'schedule': crontab(hour=14, minute=0),  # Run at 2 PM daily
    },
    'update-live-odds': {
        'task': 'tasks.data.update_odds',
        'schedule': crontab(minute='*/15'),  # Every 15 minutes
    },
}
```

---

## Q: What is the project folder structure?

A: Here's the recommended monorepo structure:

```text
filterbets/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ config.py               # Settings & env vars
â”‚   â”‚   â”œâ”€â”€ database.py             # DB connection & session
â”‚   â”‚   â”œâ”€â”€ models/                 # SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixture.py
â”‚   â”‚   â”‚   â”œâ”€â”€ filter.py
â”‚   â”‚   â”‚   â””â”€â”€ team.py
â”‚   â”‚   â”œâ”€â”€ schemas/                # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixture.py
â”‚   â”‚   â”‚   â””â”€â”€ filter.py
â”‚   â”‚   â”œâ”€â”€ api/                    # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixtures.py
â”‚   â”‚   â”‚   â”œâ”€â”€ filters.py
â”‚   â”‚   â”‚   â””â”€â”€ scanner.py
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ backtest.py
â”‚   â”‚   â”‚   â”œâ”€â”€ filter_engine.py
â”‚   â”‚   â”‚   â””â”€â”€ stats_calculator.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ security.py
â”‚   â”œâ”€â”€ tasks/                      # Celery tasks
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ celery_app.py
â”‚   â”‚   â”œâ”€â”€ notifications.py
â”‚   â”‚   â””â”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ bot/                        # Telegram bot
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ telegram_bot.py
â”‚   â”œâ”€â”€ alembic/                    # DB migrations
â”‚   â”‚   â”œâ”€â”€ versions/
â”‚   â”‚   â””â”€â”€ env.py
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ api/                    # TanStack Query hooks
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_prototyping.ipynb
â”œâ”€â”€ data/                           # Kaggle datasets (gitignored)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.prod.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml
â”‚       â””â”€â”€ deploy.yml
â””â”€â”€ docs/
    â”œâ”€â”€ DISCUTIONS.md
    â”œâ”€â”€ API.md
    â””â”€â”€ SETUP.md
```

---

## Q: What are the MVP features vs future features?

A: Here's the phased roadmap:

### Phase 1: MVP (4-6 weeks)

- [ ] User authentication (register, login, JWT)
- [ ] Data ingestion pipeline from Kaggle CSV
- [ ] Basic fixtures listing with filters (league, date)
- [ ] Team statistics display
- [ ] Filter creation (basic criteria: league, odds, form)
- [ ] Simple backtesting (win rate, ROI)
- [ ] Basic responsive UI

### Phase 2: Core Features (4-6 weeks)

- [ ] Telegram bot integration & notifications
- [ ] Pre-match scanner with scheduled runs
- [ ] Advanced filter criteria (H2H, home/away splits)
- [ ] Detailed backtest analytics (streaks, monthly breakdown)
- [ ] Filter sharing (public filters)
- [ ] Trending/popular filters feed

### Phase 3: Premium Features (4-6 weeks)

- [ ] Subscription system (Stripe integration)
- [ ] Live scanner (requires real-time data API)
- [ ] Value bet detection algorithm
- [ ] Excel export functionality
- [ ] API access for Pro users
- [ ] Advanced stats (xG, corners, cards)

### Phase 4: Growth & Polish (Ongoing)

- [ ] Mobile app (React Native or PWA)
- [ ] Social features (follow users, leaderboards)
- [ ] ML-powered prediction improvements
- [ ] Multi-language support
- [ ] Affiliate/referral program

---

## Q: What are the key risks and mitigations?

A: Here are the main risks to consider:

| Risk | Impact | Mitigation |
| ------ | -------- | ------------ |
| **Data quality issues** | High - bad data = bad predictions | Implement data validation, anomaly detection, manual review process |
| **Real-time API costs** | Medium - can get expensive | Start with delayed data, negotiate volume discounts, cache aggressively |
| **Legal/regulatory** | High - gambling laws vary by region | Add disclaimers, geo-restrict if needed, consult legal counsel |
| **Scalability** | Medium - backtesting can be heavy | Use Celery for async, implement query caching, optimize DB indexes |
| **User trust** | High - users need to trust predictions | Show transparent backtest results, track record, no false promises |
| **Telegram rate limits** | Low - can hit API limits | Implement rate limiting, batch notifications, use webhooks |

---

## Q: What Kaggle datasets are recommended?

A: Here are quality datasets to start with:

1. **Football-Data.co.uk** (via Kaggle mirrors)
   - 25+ years of match results
   - Odds from multiple bookmakers
   - Major European leagues

2. **European Soccer Database** (Kaggle)
   - 25,000+ matches
   - Player attributes
   - Team attributes
   - Betting odds

3. **International Football Results** (Kaggle)
   - 45,000+ international matches
   - Good for international tournaments

4. **Football Events** (Kaggle)
   - Detailed match events
   - Goals, cards, substitutions

**Data Update Strategy:**

- Football-Data.co.uk updates weekly during season
- Set up automated download script
- Consider API-Football.com for real-time data (paid)
